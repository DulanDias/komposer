{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Komposer - Automated Musical Note Generation based on Lyrics with Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. S. Dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 280\n",
      "Number of unique input tokens: 62\n",
      "Number of unique output tokens: 40\n",
      "Max sequence length for inputs: 75\n",
      "Max sequence length for outputs: 76\n",
      "Epoch 1/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 1.7711\n",
      "Epoch 2/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 1.3192\n",
      "Epoch 3/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 1.2901\n",
      "Epoch 4/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 1.2889\n",
      "Epoch 5/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 1.2767\n",
      "Epoch 6/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 1.2702\n",
      "Epoch 7/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 1.2694\n",
      "Epoch 8/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 1.2510\n",
      "Epoch 9/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 1.2487\n",
      "Epoch 10/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 1.2426\n",
      "Epoch 11/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 1.2305\n",
      "Epoch 12/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 1.2214\n",
      "Epoch 13/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 1.2016\n",
      "Epoch 14/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 1.1675\n",
      "Epoch 15/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 1.1482\n",
      "Epoch 16/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 1.1382\n",
      "Epoch 17/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 1.1067\n",
      "Epoch 18/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 1.0973\n",
      "Epoch 19/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 1.0771\n",
      "Epoch 20/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 1.1668\n",
      "Epoch 21/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 1.0577\n",
      "Epoch 22/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 1.0156\n",
      "Epoch 23/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.9833\n",
      "Epoch 24/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.9776\n",
      "Epoch 25/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.9528\n",
      "Epoch 26/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.9471\n",
      "Epoch 27/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.9206\n",
      "Epoch 28/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.9087\n",
      "Epoch 29/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.9082\n",
      "Epoch 30/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.8822\n",
      "Epoch 31/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.8782\n",
      "Epoch 32/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.8641\n",
      "Epoch 33/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.8440\n",
      "Epoch 34/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.8416\n",
      "Epoch 35/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.8415\n",
      "Epoch 36/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.8334\n",
      "Epoch 37/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.8083\n",
      "Epoch 38/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.7863\n",
      "Epoch 39/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.8088\n",
      "Epoch 40/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.7761\n",
      "Epoch 41/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.7738\n",
      "Epoch 42/1000\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.7595\n",
      "Epoch 43/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.7515\n",
      "Epoch 44/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.7586\n",
      "Epoch 45/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.7233\n",
      "Epoch 46/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.7388\n",
      "Epoch 47/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.7174\n",
      "Epoch 48/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.7157\n",
      "Epoch 49/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.6983\n",
      "Epoch 50/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.6930\n",
      "Epoch 51/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.6986\n",
      "Epoch 52/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.6865\n",
      "Epoch 53/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.6610\n",
      "Epoch 54/1000\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.6605\n",
      "Epoch 55/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.6621\n",
      "Epoch 56/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.6581\n",
      "Epoch 57/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.6337\n",
      "Epoch 58/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.6295\n",
      "Epoch 59/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.6365\n",
      "Epoch 60/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.6082\n",
      "Epoch 61/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.6203\n",
      "Epoch 62/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.5996\n",
      "Epoch 63/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.6032\n",
      "Epoch 64/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.6561\n",
      "Epoch 65/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.6849\n",
      "Epoch 66/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.6527\n",
      "Epoch 67/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.6581\n",
      "Epoch 68/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.6017\n",
      "Epoch 69/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.5807\n",
      "Epoch 70/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.5834\n",
      "Epoch 71/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.5710\n",
      "Epoch 72/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.5568\n",
      "Epoch 73/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.5653\n",
      "Epoch 74/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.5364\n",
      "Epoch 75/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.5348\n",
      "Epoch 76/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.5187\n",
      "Epoch 77/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.5100\n",
      "Epoch 78/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.5052\n",
      "Epoch 79/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.5230\n",
      "Epoch 80/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.4933\n",
      "Epoch 81/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.4915\n",
      "Epoch 82/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.4841\n",
      "Epoch 83/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.4762\n",
      "Epoch 84/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.4730\n",
      "Epoch 85/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.4930\n",
      "Epoch 86/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.4451\n",
      "Epoch 87/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.4461\n",
      "Epoch 88/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.4551\n",
      "Epoch 89/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.4431\n",
      "Epoch 90/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.4362\n",
      "Epoch 91/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.4242\n",
      "Epoch 92/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.4207\n",
      "Epoch 93/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.4314\n",
      "Epoch 94/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.4055\n",
      "Epoch 95/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.4073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.4059\n",
      "Epoch 97/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.3894\n",
      "Epoch 98/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.3848\n",
      "Epoch 99/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.3947\n",
      "Epoch 100/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.3787\n",
      "Epoch 101/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.3867\n",
      "Epoch 102/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.3647\n",
      "Epoch 103/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.3702\n",
      "Epoch 104/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.3551\n",
      "Epoch 105/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.3687\n",
      "Epoch 106/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.3406\n",
      "Epoch 107/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.3523\n",
      "Epoch 108/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.3351\n",
      "Epoch 109/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.3371\n",
      "Epoch 110/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.3421\n",
      "Epoch 111/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.3358\n",
      "Epoch 112/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.3184\n",
      "Epoch 113/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.3287\n",
      "Epoch 114/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.3092\n",
      "Epoch 115/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.3047\n",
      "Epoch 116/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.3081\n",
      "Epoch 117/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.3100\n",
      "Epoch 118/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.3047\n",
      "Epoch 119/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.2926\n",
      "Epoch 120/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.3072\n",
      "Epoch 121/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.2920\n",
      "Epoch 122/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.2838\n",
      "Epoch 123/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.2759\n",
      "Epoch 124/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.2812\n",
      "Epoch 125/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.2682\n",
      "Epoch 126/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.2740\n",
      "Epoch 127/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.2646\n",
      "Epoch 128/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.2651\n",
      "Epoch 129/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.2597\n",
      "Epoch 130/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.2653\n",
      "Epoch 131/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.2651\n",
      "Epoch 132/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.2449\n",
      "Epoch 133/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.2397\n",
      "Epoch 134/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.2483\n",
      "Epoch 135/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.2350\n",
      "Epoch 136/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.2456\n",
      "Epoch 137/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.2506\n",
      "Epoch 138/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.2308\n",
      "Epoch 139/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.2283\n",
      "Epoch 140/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.2304\n",
      "Epoch 141/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.2197\n",
      "Epoch 142/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.2252\n",
      "Epoch 143/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.2222\n",
      "Epoch 144/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.2187\n",
      "Epoch 145/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.2157\n",
      "Epoch 146/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.2105\n",
      "Epoch 147/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.2094\n",
      "Epoch 148/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.2069\n",
      "Epoch 149/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.2051\n",
      "Epoch 150/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.2051\n",
      "Epoch 151/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.2033\n",
      "Epoch 152/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.1898\n",
      "Epoch 153/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.1931\n",
      "Epoch 154/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.1958\n",
      "Epoch 155/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.1957\n",
      "Epoch 156/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.1863\n",
      "Epoch 157/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.1837\n",
      "Epoch 158/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.1891\n",
      "Epoch 159/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.1850\n",
      "Epoch 160/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.1738\n",
      "Epoch 161/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.1809\n",
      "Epoch 162/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.1741\n",
      "Epoch 163/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.1769\n",
      "Epoch 164/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.1763\n",
      "Epoch 165/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.1755\n",
      "Epoch 166/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.1684\n",
      "Epoch 167/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.1592\n",
      "Epoch 168/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.1635\n",
      "Epoch 169/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.1634\n",
      "Epoch 170/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.1568\n",
      "Epoch 171/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.1616\n",
      "Epoch 172/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.1568\n",
      "Epoch 173/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.1577\n",
      "Epoch 174/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.1555\n",
      "Epoch 175/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.1492\n",
      "Epoch 176/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.1622\n",
      "Epoch 177/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.1506\n",
      "Epoch 178/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.1460\n",
      "Epoch 179/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.1493\n",
      "Epoch 180/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.1425\n",
      "Epoch 181/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.1440\n",
      "Epoch 182/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.1479\n",
      "Epoch 183/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.1328\n",
      "Epoch 184/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.1450\n",
      "Epoch 185/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.1441\n",
      "Epoch 186/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.1622\n",
      "Epoch 187/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.1284\n",
      "Epoch 188/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.1243\n",
      "Epoch 189/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.1322\n",
      "Epoch 190/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.1431\n",
      "Epoch 191/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.1592\n",
      "Epoch 192/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.1230\n",
      "Epoch 193/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.1206\n",
      "Epoch 194/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.1201\n",
      "Epoch 195/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.1259\n",
      "Epoch 196/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.1224\n",
      "Epoch 197/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.1312\n",
      "Epoch 198/1000\n",
      "280/280 [==============================] - 5s 19ms/step - loss: 0.1360\n",
      "Epoch 199/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.1179\n",
      "Epoch 200/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.1267\n",
      "Epoch 201/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.1191\n",
      "Epoch 202/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.1147\n",
      "Epoch 203/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.1272\n",
      "Epoch 204/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.1258\n",
      "Epoch 205/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.1087\n",
      "Epoch 206/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.1185\n",
      "Epoch 207/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.1119\n",
      "Epoch 208/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.1296\n",
      "Epoch 209/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.1124\n",
      "Epoch 210/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.1125\n",
      "Epoch 211/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.1065\n",
      "Epoch 212/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.1150\n",
      "Epoch 213/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.1087\n",
      "Epoch 214/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.1056\n",
      "Epoch 215/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.1105\n",
      "Epoch 216/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.1186\n",
      "Epoch 217/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.1056\n",
      "Epoch 218/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.1051\n",
      "Epoch 219/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.1029\n",
      "Epoch 220/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.1047\n",
      "Epoch 221/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.1086\n",
      "Epoch 222/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.1008\n",
      "Epoch 223/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.1046\n",
      "Epoch 224/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0974\n",
      "Epoch 225/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.1002\n",
      "Epoch 226/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.1085\n",
      "Epoch 227/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.1022\n",
      "Epoch 228/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0968\n",
      "Epoch 229/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0981\n",
      "Epoch 230/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0950\n",
      "Epoch 231/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.1040\n",
      "Epoch 232/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0971\n",
      "Epoch 233/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.1093\n",
      "Epoch 234/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0919\n",
      "Epoch 235/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0960\n",
      "Epoch 236/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0878\n",
      "Epoch 237/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.1019\n",
      "Epoch 238/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0960\n",
      "Epoch 239/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0951\n",
      "Epoch 240/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0897\n",
      "Epoch 241/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0916\n",
      "Epoch 242/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0913\n",
      "Epoch 243/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0929\n",
      "Epoch 244/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0904\n",
      "Epoch 245/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0904\n",
      "Epoch 246/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0864\n",
      "Epoch 247/1000\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.0869\n",
      "Epoch 248/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0909\n",
      "Epoch 249/1000\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.0970\n",
      "Epoch 250/1000\n",
      "280/280 [==============================] - 5s 18ms/step - loss: 0.0822\n",
      "Epoch 251/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0898\n",
      "Epoch 252/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0867\n",
      "Epoch 253/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0890\n",
      "Epoch 254/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0788\n",
      "Epoch 255/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.1031\n",
      "Epoch 256/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0854\n",
      "Epoch 257/1000\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 0.0811\n",
      "Epoch 258/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0817\n",
      "Epoch 259/1000\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 0.0876\n",
      "Epoch 260/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0775\n",
      "Epoch 261/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0866\n",
      "Epoch 262/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0885\n",
      "Epoch 263/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0840\n",
      "Epoch 264/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0802\n",
      "Epoch 265/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0813\n",
      "Epoch 266/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0807\n",
      "Epoch 267/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0756\n",
      "Epoch 268/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0863\n",
      "Epoch 269/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0882\n",
      "Epoch 270/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0777\n",
      "Epoch 271/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0761\n",
      "Epoch 272/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0791\n",
      "Epoch 273/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0730\n",
      "Epoch 274/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0784\n",
      "Epoch 275/1000\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 0.0851\n",
      "Epoch 276/1000\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 0.0782\n",
      "Epoch 277/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0853\n",
      "Epoch 278/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0785\n",
      "Epoch 279/1000\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 0.0733\n",
      "Epoch 280/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0779\n",
      "Epoch 281/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0762\n",
      "Epoch 282/1000\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.0785\n",
      "Epoch 283/1000\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 0.0716\n",
      "Epoch 284/1000\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 0.0800\n",
      "Epoch 285/1000\n",
      "280/280 [==============================] - 5s 16ms/step - loss: 0.0710\n",
      "Epoch 286/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 5s 17ms/step - loss: 0.0839\n",
      "Epoch 287/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0742\n",
      "Epoch 288/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0732\n",
      "Epoch 289/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0768\n",
      "Epoch 290/1000\n",
      "280/280 [==============================] - 5s 16ms/step - loss: 0.0690\n",
      "Epoch 291/1000\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 0.0794\n",
      "Epoch 292/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0767\n",
      "Epoch 293/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0782\n",
      "Epoch 294/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0718\n",
      "Epoch 295/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0692\n",
      "Epoch 296/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0721\n",
      "Epoch 297/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0699\n",
      "Epoch 298/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0711\n",
      "Epoch 299/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0712\n",
      "Epoch 300/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0660\n",
      "Epoch 301/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0814\n",
      "Epoch 302/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0648\n",
      "Epoch 303/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0654\n",
      "Epoch 304/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0754\n",
      "Epoch 305/1000\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 0.0664\n",
      "Epoch 306/1000\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.0794\n",
      "Epoch 307/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0653\n",
      "Epoch 308/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0640\n",
      "Epoch 309/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0737\n",
      "Epoch 310/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0622\n",
      "Epoch 311/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0794\n",
      "Epoch 312/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0636\n",
      "Epoch 313/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0691\n",
      "Epoch 314/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0684\n",
      "Epoch 315/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0646\n",
      "Epoch 316/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0703\n",
      "Epoch 317/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0676\n",
      "Epoch 318/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0710\n",
      "Epoch 319/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0634\n",
      "Epoch 320/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0685\n",
      "Epoch 321/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0719\n",
      "Epoch 322/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0703\n",
      "Epoch 323/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0951\n",
      "Epoch 324/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0600\n",
      "Epoch 325/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0578\n",
      "Epoch 326/1000\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 0.0676\n",
      "Epoch 327/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0645\n",
      "Epoch 328/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0596\n",
      "Epoch 329/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0646\n",
      "Epoch 330/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0677\n",
      "Epoch 331/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0675\n",
      "Epoch 332/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0647\n",
      "Epoch 333/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0594\n",
      "Epoch 334/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0594\n",
      "Epoch 335/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0696\n",
      "Epoch 336/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0611\n",
      "Epoch 337/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0649\n",
      "Epoch 338/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0615\n",
      "Epoch 339/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0764\n",
      "Epoch 340/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0709\n",
      "Epoch 341/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0641\n",
      "Epoch 342/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0588\n",
      "Epoch 343/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0551\n",
      "Epoch 344/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0591\n",
      "Epoch 345/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0672\n",
      "Epoch 346/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0549\n",
      "Epoch 347/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0655\n",
      "Epoch 348/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0659\n",
      "Epoch 349/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0571\n",
      "Epoch 350/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0622\n",
      "Epoch 351/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0544\n",
      "Epoch 352/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0670\n",
      "Epoch 353/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0582\n",
      "Epoch 354/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0583\n",
      "Epoch 355/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0652\n",
      "Epoch 356/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0594\n",
      "Epoch 357/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0613\n",
      "Epoch 358/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0559\n",
      "Epoch 359/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0618\n",
      "Epoch 360/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0558\n",
      "Epoch 361/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0717\n",
      "Epoch 362/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0596\n",
      "Epoch 363/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0559\n",
      "Epoch 364/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0570\n",
      "Epoch 365/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0546\n",
      "Epoch 366/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0596\n",
      "Epoch 367/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0591\n",
      "Epoch 368/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0546\n",
      "Epoch 369/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0603\n",
      "Epoch 370/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0556\n",
      "Epoch 371/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0552\n",
      "Epoch 372/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0528\n",
      "Epoch 373/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0626\n",
      "Epoch 374/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0523\n",
      "Epoch 375/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0528\n",
      "Epoch 376/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0557\n",
      "Epoch 377/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0836\n",
      "Epoch 378/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0543\n",
      "Epoch 379/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0470\n",
      "Epoch 380/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0651\n",
      "Epoch 381/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0503\n",
      "Epoch 382/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0494\n",
      "Epoch 383/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0580\n",
      "Epoch 384/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0555\n",
      "Epoch 385/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0482\n",
      "Epoch 386/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0526\n",
      "Epoch 387/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0601\n",
      "Epoch 388/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0512\n",
      "Epoch 389/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0487\n",
      "Epoch 390/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0620\n",
      "Epoch 391/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0508\n",
      "Epoch 392/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0507\n",
      "Epoch 393/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0505\n",
      "Epoch 394/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0652\n",
      "Epoch 395/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0633\n",
      "Epoch 396/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0499\n",
      "Epoch 397/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0531\n",
      "Epoch 398/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0528\n",
      "Epoch 399/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0461\n",
      "Epoch 400/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0500\n",
      "Epoch 401/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0583\n",
      "Epoch 402/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0464\n",
      "Epoch 403/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0482\n",
      "Epoch 404/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0614\n",
      "Epoch 405/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0489\n",
      "Epoch 406/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0451\n",
      "Epoch 407/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0576\n",
      "Epoch 408/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0496\n",
      "Epoch 409/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0474\n",
      "Epoch 410/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0594\n",
      "Epoch 411/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0481\n",
      "Epoch 412/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0516\n",
      "Epoch 413/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0498\n",
      "Epoch 414/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0484\n",
      "Epoch 415/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0551\n",
      "Epoch 416/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0453\n",
      "Epoch 417/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0519\n",
      "Epoch 418/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0458\n",
      "Epoch 419/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0513\n",
      "Epoch 420/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0497\n",
      "Epoch 421/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0438\n",
      "Epoch 422/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0523\n",
      "Epoch 423/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0527\n",
      "Epoch 424/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0479\n",
      "Epoch 425/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0628\n",
      "Epoch 426/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0453\n",
      "Epoch 427/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0473\n",
      "Epoch 428/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0418\n",
      "Epoch 429/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0566\n",
      "Epoch 430/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0417\n",
      "Epoch 431/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0459\n",
      "Epoch 432/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0470\n",
      "Epoch 433/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0505\n",
      "Epoch 434/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0427\n",
      "Epoch 435/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0599\n",
      "Epoch 436/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0457\n",
      "Epoch 437/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0403\n",
      "Epoch 438/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0517\n",
      "Epoch 439/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0471\n",
      "Epoch 440/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0631\n",
      "Epoch 441/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0461\n",
      "Epoch 442/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0416\n",
      "Epoch 443/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0508\n",
      "Epoch 444/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0443\n",
      "Epoch 445/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0399\n",
      "Epoch 446/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0485\n",
      "Epoch 447/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0472\n",
      "Epoch 448/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0464\n",
      "Epoch 449/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0411\n",
      "Epoch 450/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0567\n",
      "Epoch 451/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0408\n",
      "Epoch 452/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0394\n",
      "Epoch 453/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0515\n",
      "Epoch 454/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0429\n",
      "Epoch 455/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0401\n",
      "Epoch 456/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0399\n",
      "Epoch 457/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0609\n",
      "Epoch 458/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0475\n",
      "Epoch 459/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0401\n",
      "Epoch 460/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0375\n",
      "Epoch 461/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0569\n",
      "Epoch 462/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0454\n",
      "Epoch 463/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0392\n",
      "Epoch 464/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0442\n",
      "Epoch 465/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0418\n",
      "Epoch 466/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0400\n",
      "Epoch 467/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0396\n",
      "Epoch 468/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0539\n",
      "Epoch 469/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0376\n",
      "Epoch 470/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0386\n",
      "Epoch 471/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0394\n",
      "Epoch 472/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0581\n",
      "Epoch 473/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0512\n",
      "Epoch 474/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0394\n",
      "Epoch 475/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0442\n",
      "Epoch 476/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0392\n",
      "Epoch 477/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0333\n",
      "Epoch 478/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0397\n",
      "Epoch 479/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0460\n",
      "Epoch 480/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0437\n",
      "Epoch 481/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0356\n",
      "Epoch 482/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0351\n",
      "Epoch 483/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0664\n",
      "Epoch 484/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0400\n",
      "Epoch 485/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0352\n",
      "Epoch 486/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0347\n",
      "Epoch 487/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0356\n",
      "Epoch 488/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0589\n",
      "Epoch 489/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0359\n",
      "Epoch 490/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0386\n",
      "Epoch 491/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0371\n",
      "Epoch 492/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0424\n",
      "Epoch 493/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0404\n",
      "Epoch 494/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0335\n",
      "Epoch 495/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0427\n",
      "Epoch 496/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0473\n",
      "Epoch 497/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0349\n",
      "Epoch 498/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0353\n",
      "Epoch 499/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0416\n",
      "Epoch 500/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0351\n",
      "Epoch 501/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0459\n",
      "Epoch 502/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0358\n",
      "Epoch 503/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0362\n",
      "Epoch 504/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0492\n",
      "Epoch 505/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0367\n",
      "Epoch 506/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0439\n",
      "Epoch 507/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0340\n",
      "Epoch 508/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0396\n",
      "Epoch 509/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0334\n",
      "Epoch 510/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0460\n",
      "Epoch 511/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0362\n",
      "Epoch 512/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0311\n",
      "Epoch 513/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0457\n",
      "Epoch 514/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0404\n",
      "Epoch 515/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0312\n",
      "Epoch 516/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0328\n",
      "Epoch 517/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0451\n",
      "Epoch 518/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0321\n",
      "Epoch 519/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0327\n",
      "Epoch 520/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0479\n",
      "Epoch 521/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0487\n",
      "Epoch 522/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0316\n",
      "Epoch 523/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0327\n",
      "Epoch 524/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0334\n",
      "Epoch 525/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0380\n",
      "Epoch 526/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0347\n",
      "Epoch 527/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0335\n",
      "Epoch 528/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0326\n",
      "Epoch 529/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0366\n",
      "Epoch 530/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0321\n",
      "Epoch 531/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0489\n",
      "Epoch 532/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0333\n",
      "Epoch 533/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0289\n",
      "Epoch 534/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0286\n",
      "Epoch 535/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0499\n",
      "Epoch 536/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0390\n",
      "Epoch 537/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0377\n",
      "Epoch 538/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0328\n",
      "Epoch 539/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0300\n",
      "Epoch 540/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0432\n",
      "Epoch 541/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0421\n",
      "Epoch 542/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0306\n",
      "Epoch 543/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0309\n",
      "Epoch 544/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0411\n",
      "Epoch 545/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0347\n",
      "Epoch 546/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0388\n",
      "Epoch 547/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0298\n",
      "Epoch 548/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0438\n",
      "Epoch 549/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0323\n",
      "Epoch 550/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0286\n",
      "Epoch 551/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0436\n",
      "Epoch 552/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0319\n",
      "Epoch 553/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0286\n",
      "Epoch 554/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0275\n",
      "Epoch 555/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0455\n",
      "Epoch 556/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0348\n",
      "Epoch 557/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0280\n",
      "Epoch 558/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0301\n",
      "Epoch 559/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0465\n",
      "Epoch 560/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0306\n",
      "Epoch 561/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0389\n",
      "Epoch 562/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0273\n",
      "Epoch 563/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0321\n",
      "Epoch 564/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0448\n",
      "Epoch 565/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0293\n",
      "Epoch 566/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0290\n",
      "Epoch 567/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0258\n",
      "Epoch 568/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0430\n",
      "Epoch 569/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0328\n",
      "Epoch 570/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0279\n",
      "Epoch 571/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0271\n",
      "Epoch 572/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0431\n",
      "Epoch 573/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0289\n",
      "Epoch 574/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0275\n",
      "Epoch 575/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0315\n",
      "Epoch 576/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0350\n",
      "Epoch 577/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0258\n",
      "Epoch 578/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0407\n",
      "Epoch 579/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0329\n",
      "Epoch 580/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0252\n",
      "Epoch 581/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0270\n",
      "Epoch 582/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0363\n",
      "Epoch 583/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0368\n",
      "Epoch 584/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0265\n",
      "Epoch 585/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0243\n",
      "Epoch 586/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0250\n",
      "Epoch 587/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0506\n",
      "Epoch 588/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0392\n",
      "Epoch 589/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0257\n",
      "Epoch 590/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0236\n",
      "Epoch 591/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0368\n",
      "Epoch 592/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0293\n",
      "Epoch 593/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0254\n",
      "Epoch 594/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0234\n",
      "Epoch 595/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0376\n",
      "Epoch 596/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0308\n",
      "Epoch 597/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0249\n",
      "Epoch 598/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0360\n",
      "Epoch 599/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0293\n",
      "Epoch 600/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0348\n",
      "Epoch 601/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0236\n",
      "Epoch 602/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0229\n",
      "Epoch 603/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0347\n",
      "Epoch 604/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0380\n",
      "Epoch 605/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0278\n",
      "Epoch 606/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0282\n",
      "Epoch 607/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0229\n",
      "Epoch 608/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0381\n",
      "Epoch 609/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0265\n",
      "Epoch 610/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0229\n",
      "Epoch 611/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0231\n",
      "Epoch 612/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0297\n",
      "Epoch 613/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0423\n",
      "Epoch 614/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0294\n",
      "Epoch 615/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0248\n",
      "Epoch 616/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0236\n",
      "Epoch 617/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0377\n",
      "Epoch 618/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0336\n",
      "Epoch 619/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0243\n",
      "Epoch 620/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0231\n",
      "Epoch 621/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0230\n",
      "Epoch 622/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0478\n",
      "Epoch 623/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0261\n",
      "Epoch 624/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0274\n",
      "Epoch 625/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0238\n",
      "Epoch 626/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0268\n",
      "Epoch 627/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0380\n",
      "Epoch 628/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0250\n",
      "Epoch 629/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0228\n",
      "Epoch 630/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0233\n",
      "Epoch 631/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0440\n",
      "Epoch 632/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0250\n",
      "Epoch 633/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0221\n",
      "Epoch 634/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0254\n",
      "Epoch 635/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0349\n",
      "Epoch 636/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0393\n",
      "Epoch 637/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0235\n",
      "Epoch 638/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0214\n",
      "Epoch 639/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0212\n",
      "Epoch 640/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0250\n",
      "Epoch 641/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0301\n",
      "Epoch 642/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0290\n",
      "Epoch 643/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0342\n",
      "Epoch 644/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0232\n",
      "Epoch 645/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0233\n",
      "Epoch 646/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0374\n",
      "Epoch 647/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0257\n",
      "Epoch 648/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0210\n",
      "Epoch 649/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0209\n",
      "Epoch 650/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0212\n",
      "Epoch 651/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0459\n",
      "Epoch 652/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0275\n",
      "Epoch 653/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0218\n",
      "Epoch 654/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0221\n",
      "Epoch 655/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0246\n",
      "Epoch 656/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0348\n",
      "Epoch 657/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0229\n",
      "Epoch 658/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0248\n",
      "Epoch 659/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0410\n",
      "Epoch 660/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0265\n",
      "Epoch 661/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0216\n",
      "Epoch 662/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0212\n",
      "Epoch 663/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0235\n",
      "Epoch 664/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0371\n",
      "Epoch 665/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0225\n",
      "Epoch 666/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0211\n",
      "Epoch 667/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0211\n",
      "Epoch 668/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0214\n",
      "Epoch 669/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0330\n",
      "Epoch 670/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0395\n",
      "Epoch 671/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0230\n",
      "Epoch 672/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0247\n",
      "Epoch 673/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0227\n",
      "Epoch 674/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0213\n",
      "Epoch 675/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0354\n",
      "Epoch 676/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0221\n",
      "Epoch 677/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0203\n",
      "Epoch 678/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0202\n",
      "Epoch 679/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0204\n",
      "Epoch 680/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0288\n",
      "Epoch 681/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0355\n",
      "Epoch 682/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0300\n",
      "Epoch 683/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0212\n",
      "Epoch 684/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0207\n",
      "Epoch 685/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0253\n",
      "Epoch 686/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0442\n",
      "Epoch 687/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0257\n",
      "Epoch 688/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0207\n",
      "Epoch 689/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0201\n",
      "Epoch 690/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0200\n",
      "Epoch 691/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0305\n",
      "Epoch 692/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0268\n",
      "Epoch 693/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0212\n",
      "Epoch 694/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0217\n",
      "Epoch 695/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0199\n",
      "Epoch 696/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0227\n",
      "Epoch 697/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0385\n",
      "Epoch 698/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0214\n",
      "Epoch 699/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0210\n",
      "Epoch 700/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0209\n",
      "Epoch 701/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0247\n",
      "Epoch 702/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0333\n",
      "Epoch 703/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0206\n",
      "Epoch 704/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0209\n",
      "Epoch 705/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0234\n",
      "Epoch 706/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0324\n",
      "Epoch 707/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0281\n",
      "Epoch 708/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0198\n",
      "Epoch 709/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0192\n",
      "Epoch 710/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0315\n",
      "Epoch 711/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0271\n",
      "Epoch 712/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0196\n",
      "Epoch 713/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0193\n",
      "Epoch 714/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0207\n",
      "Epoch 715/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0391\n",
      "Epoch 716/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0275\n",
      "Epoch 717/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0197\n",
      "Epoch 718/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0201\n",
      "Epoch 719/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0196\n",
      "Epoch 720/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0207\n",
      "Epoch 721/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0264\n",
      "Epoch 722/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0295\n",
      "Epoch 723/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0202\n",
      "Epoch 724/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0227\n",
      "Epoch 725/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0203\n",
      "Epoch 726/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0349\n",
      "Epoch 727/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0269\n",
      "Epoch 728/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0192\n",
      "Epoch 729/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0194\n",
      "Epoch 730/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0193\n",
      "Epoch 731/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0362\n",
      "Epoch 732/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0237\n",
      "Epoch 733/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0198\n",
      "Epoch 734/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0195\n",
      "Epoch 735/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0250\n",
      "Epoch 736/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0278\n",
      "Epoch 737/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0190\n",
      "Epoch 738/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0188\n",
      "Epoch 739/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0189\n",
      "Epoch 740/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0235\n",
      "Epoch 741/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0363\n",
      "Epoch 742/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0198\n",
      "Epoch 743/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0196\n",
      "Epoch 744/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0189\n",
      "Epoch 745/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0212\n",
      "Epoch 746/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0378\n",
      "Epoch 747/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0200\n",
      "Epoch 748/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0185\n",
      "Epoch 749/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0196\n",
      "Epoch 750/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0192\n",
      "Epoch 751/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0196\n",
      "Epoch 752/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0405\n",
      "Epoch 753/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0215\n",
      "Epoch 754/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0190\n",
      "Epoch 755/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0189\n",
      "Epoch 756/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0186\n",
      "Epoch 757/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0191\n",
      "Epoch 758/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0194\n",
      "Epoch 759/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0416\n",
      "Epoch 760/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0207\n",
      "Epoch 761/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0199\n",
      "Epoch 762/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0192\n",
      "Epoch 763/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0205\n",
      "Epoch 764/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0227\n",
      "Epoch 765/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0381\n",
      "Epoch 766/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0205\n",
      "Epoch 767/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0180\n",
      "Epoch 768/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0232\n",
      "Epoch 769/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0195\n",
      "Epoch 770/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0180\n",
      "Epoch 771/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0181\n",
      "Epoch 772/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0288\n",
      "Epoch 773/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0288\n",
      "Epoch 774/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0184\n",
      "Epoch 775/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0181\n",
      "Epoch 776/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0180\n",
      "Epoch 777/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0184\n",
      "Epoch 778/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0185\n",
      "Epoch 779/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0312\n",
      "Epoch 780/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0239\n",
      "Epoch 781/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0194\n",
      "Epoch 782/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0193\n",
      "Epoch 783/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0216\n",
      "Epoch 784/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0210\n",
      "Epoch 785/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0241\n",
      "Epoch 786/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0280\n",
      "Epoch 787/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0185\n",
      "Epoch 788/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0184\n",
      "Epoch 789/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0181\n",
      "Epoch 790/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0183\n",
      "Epoch 791/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0190\n",
      "Epoch 792/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0213\n",
      "Epoch 793/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0335\n",
      "Epoch 794/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0189\n",
      "Epoch 795/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0183\n",
      "Epoch 796/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0180\n",
      "Epoch 797/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0191\n",
      "Epoch 798/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0193\n",
      "Epoch 799/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0283\n",
      "Epoch 800/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0269\n",
      "Epoch 801/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0206\n",
      "Epoch 802/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0192\n",
      "Epoch 803/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0207\n",
      "Epoch 804/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0193\n",
      "Epoch 805/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0184\n",
      "Epoch 806/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0338\n",
      "Epoch 807/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0192\n",
      "Epoch 808/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0188\n",
      "Epoch 809/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0179\n",
      "Epoch 810/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0175\n",
      "Epoch 811/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0192\n",
      "Epoch 812/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0413\n",
      "Epoch 813/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0232\n",
      "Epoch 814/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0180\n",
      "Epoch 815/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0174\n",
      "Epoch 816/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0174\n",
      "Epoch 817/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0176\n",
      "Epoch 818/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0180\n",
      "Epoch 819/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0237\n",
      "Epoch 820/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0377\n",
      "Epoch 821/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0214\n",
      "Epoch 822/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0180\n",
      "Epoch 823/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0174\n",
      "Epoch 824/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0176\n",
      "Epoch 825/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0176\n",
      "Epoch 826/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0298\n",
      "Epoch 827/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0279\n",
      "Epoch 828/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0204\n",
      "Epoch 829/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0184\n",
      "Epoch 830/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0177\n",
      "Epoch 831/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0179\n",
      "Epoch 832/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0219\n",
      "Epoch 833/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0346\n",
      "Epoch 834/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0305\n",
      "Epoch 835/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0194\n",
      "Epoch 836/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0175\n",
      "Epoch 837/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0172\n",
      "Epoch 838/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0173\n",
      "Epoch 839/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0172\n",
      "Epoch 840/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0174\n",
      "Epoch 841/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0304\n",
      "Epoch 842/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0231\n",
      "Epoch 843/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0194\n",
      "Epoch 844/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0178\n",
      "Epoch 845/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0174\n",
      "Epoch 846/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0177\n",
      "Epoch 847/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0203\n",
      "Epoch 848/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0346\n",
      "Epoch 849/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0200\n",
      "Epoch 850/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0179\n",
      "Epoch 851/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0175\n",
      "Epoch 852/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0175\n",
      "Epoch 853/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0240\n",
      "Epoch 854/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0241\n",
      "Epoch 855/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0176\n",
      "Epoch 856/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0181\n",
      "Epoch 857/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0192\n",
      "Epoch 858/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0187\n",
      "Epoch 859/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0179\n",
      "Epoch 860/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0313\n",
      "Epoch 861/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0211\n",
      "Epoch 862/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0182\n",
      "Epoch 863/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0193\n",
      "Epoch 864/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0176\n",
      "Epoch 865/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0176\n",
      "Epoch 866/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0227\n",
      "Epoch 867/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0457\n",
      "Epoch 868/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0233\n",
      "Epoch 869/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0177\n",
      "Epoch 870/1000\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.0176\n",
      "Epoch 871/1000\n",
      "280/280 [==============================] - 5s 16ms/step - loss: 0.0176\n",
      "Epoch 872/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0179\n",
      "Epoch 873/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0311\n",
      "Epoch 874/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0222\n",
      "Epoch 875/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0180\n",
      "Epoch 876/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0176\n",
      "Epoch 877/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0171\n",
      "Epoch 878/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0178\n",
      "Epoch 879/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0179\n",
      "Epoch 880/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0197\n",
      "Epoch 881/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0338\n",
      "Epoch 882/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0207\n",
      "Epoch 883/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0196\n",
      "Epoch 884/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0186\n",
      "Epoch 885/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0176\n",
      "Epoch 886/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0192\n",
      "Epoch 887/1000\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 0.0180\n",
      "Epoch 888/1000\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 0.0260\n",
      "Epoch 889/1000\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.0189\n",
      "Epoch 890/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0169\n",
      "Epoch 891/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0170\n",
      "Epoch 892/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0220\n",
      "Epoch 893/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0296\n",
      "Epoch 894/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0184\n",
      "Epoch 895/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0177\n",
      "Epoch 896/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0180\n",
      "Epoch 897/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0174\n",
      "Epoch 898/1000\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 0.0177\n",
      "Epoch 899/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0259\n",
      "Epoch 900/1000\n",
      "280/280 [==============================] - 4s 15ms/step - loss: 0.0209\n",
      "Epoch 901/1000\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.0187\n",
      "Epoch 902/1000\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.0178\n",
      "Epoch 903/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0173\n",
      "Epoch 904/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0178\n",
      "Epoch 905/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0183\n",
      "Epoch 906/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0185\n",
      "Epoch 907/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0275\n",
      "Epoch 908/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0194\n",
      "Epoch 909/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0235\n",
      "Epoch 910/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0201\n",
      "Epoch 911/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0188\n",
      "Epoch 912/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0171\n",
      "Epoch 913/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0167\n",
      "Epoch 914/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0191\n",
      "Epoch 915/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0253\n",
      "Epoch 916/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0175\n",
      "Epoch 917/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0171\n",
      "Epoch 918/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0171\n",
      "Epoch 919/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0193\n",
      "Epoch 920/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0209\n",
      "Epoch 921/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0268\n",
      "Epoch 922/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0176\n",
      "Epoch 923/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0175\n",
      "Epoch 924/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0167\n",
      "Epoch 925/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0173\n",
      "Epoch 926/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0196\n",
      "Epoch 927/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0208\n",
      "Epoch 928/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0174\n",
      "Epoch 929/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0169\n",
      "Epoch 930/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0212\n",
      "Epoch 931/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0206\n",
      "Epoch 932/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0171\n",
      "Epoch 933/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0176\n",
      "Epoch 934/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0335\n",
      "Epoch 935/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0394\n",
      "Epoch 936/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0219\n",
      "Epoch 937/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0202\n",
      "Epoch 938/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0170\n",
      "Epoch 939/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0165\n",
      "Epoch 940/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0166\n",
      "Epoch 941/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0168\n",
      "Epoch 942/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0168\n",
      "Epoch 943/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0311\n",
      "Epoch 944/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0198\n",
      "Epoch 945/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0172\n",
      "Epoch 946/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0169\n",
      "Epoch 947/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0180\n",
      "Epoch 948/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0171\n",
      "Epoch 949/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0171\n",
      "Epoch 950/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0181\n",
      "Epoch 951/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0245\n",
      "Epoch 952/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0243\n",
      "Epoch 953/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0192\n",
      "Epoch 954/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0167\n",
      "Epoch 955/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0162\n",
      "Epoch 956/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0164\n",
      "Epoch 957/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0164\n",
      "Epoch 958/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0191\n",
      "Epoch 959/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0336\n",
      "Epoch 960/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0172\n",
      "Epoch 961/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0164\n",
      "Epoch 962/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0167\n",
      "Epoch 963/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0168\n",
      "Epoch 964/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0169\n",
      "Epoch 965/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0232\n",
      "Epoch 966/1000\n",
      "280/280 [==============================] - 4s 13ms/step - loss: 0.0316\n",
      "Epoch 967/1000\n",
      "280/280 [==============================] - 4s 14ms/step - loss: 0.0170\n",
      "Epoch 968/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0164\n",
      "Epoch 969/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0161\n",
      "Epoch 970/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0164\n",
      "Epoch 971/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0167\n",
      "Epoch 972/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0192\n",
      "Epoch 973/1000\n",
      "280/280 [==============================] - 3s 10ms/step - loss: 0.0188\n",
      "Epoch 974/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0212\n",
      "Epoch 975/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0247\n",
      "Epoch 976/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0175\n",
      "Epoch 977/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0165\n",
      "Epoch 978/1000\n",
      "280/280 [==============================] - 3s 12ms/step - loss: 0.0163\n",
      "Epoch 979/1000\n",
      "280/280 [==============================] - 3s 11ms/step - loss: 0.0165\n",
      "Epoch 980/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0179\n",
      "Epoch 981/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0261\n",
      "Epoch 982/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0177\n",
      "Epoch 983/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0167\n",
      "Epoch 984/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0169\n",
      "Epoch 985/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0168\n",
      "Epoch 986/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0169\n",
      "Epoch 987/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0306\n",
      "Epoch 988/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0221\n",
      "Epoch 989/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0168\n",
      "Epoch 990/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0164\n",
      "Epoch 991/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0162\n",
      "Epoch 992/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0164\n",
      "Epoch 993/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0244\n",
      "Epoch 994/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0203\n",
      "Epoch 995/1000\n",
      "280/280 [==============================] - 2s 9ms/step - loss: 0.0166\n",
      "Epoch 996/1000\n",
      "280/280 [==============================] - 3s 9ms/step - loss: 0.0171\n",
      "Epoch 997/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0164\n",
      "Epoch 998/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0169\n",
      "Epoch 999/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0174\n",
      "Epoch 1000/1000\n",
      "280/280 [==============================] - 2s 8ms/step - loss: 0.0180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Mac/anaconda2/envs/komposer/lib/python2.7/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_3/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/Volumes/Mac/anaconda2/envs/komposer/lib/python2.7/site-packages/keras/engine/network.py:888: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_7:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'input_8:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 1000  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = 'music/data-special.txt'\n",
    "\n",
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.0)\n",
    "\n",
    "keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=2,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "# Save model\n",
    "model.save('l2n-1000-special.h5')\n",
    "\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "encoder_model.save('l2n-1000-special_encoder.h5')\n",
    "decoder_model.save('l2n-1000-special_decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, None, 62)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, None, 40)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 256), (None, 326656      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 256),  304128      input_6[0][0]                    \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 40)     10280       lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 641,064\n",
      "Trainable params: 641,064\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, None, 62)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                [(None, 256), (None, 256) 326656    \n",
      "=================================================================\n",
      "Total params: 326,656\n",
      "Trainable params: 326,656\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(encoder_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, None, 40)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 256),  304128      input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 40)     10280       lstm_4[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 314,408\n",
      "Trainable params: 314,408\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(decoder_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model\n",
    "#plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize model\n",
    "#plot_model(encoder_model, to_file='encoder_lstm.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize model\n",
    "#plot_model(decoder_model, to_file='decoder_lstm.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.7711375100272042, 1.3192261184964862, 1.2900513819285802, 1.2888921737670898, 1.2767407723835535, 1.2701502016612463, 1.2693572759628295, 1.2509625060217722, 1.2486987284251623, 1.2426311186381749, 1.2304729904447282, 1.2214074986321586, 1.2015764236450195, 1.1675060817173548, 1.1482017074312483, 1.1381572587149484, 1.106669739314488, 1.0972817999976021, 1.0770943249974931, 1.1668499946594237, 1.0577029296330043, 1.015588743346078, 0.9832754407610212, 0.9775690606662205, 0.9528151665415082, 0.9471382362501962, 0.9206307343074254, 0.9086937478610447, 0.9082128405570984, 0.8821607317243304, 0.8782417297363281, 0.8641336168561663, 0.8439540403229849, 0.841637202671596, 0.8415052022252764, 0.8333847267287118, 0.8083421724183218, 0.7863431743213108, 0.8088376607213702, 0.7761088149888175, 0.7738383037703378, 0.7595394679478237, 0.7514616404260908, 0.7586073858397347, 0.7232557024274554, 0.738838085106441, 0.7173690915107727, 0.7157347593988691, 0.6983035104615348, 0.6930057610784258, 0.6985517365591867, 0.6864732878548758, 0.6610156042235238, 0.6604844161442348, 0.6620808209691729, 0.6580591525350298, 0.6336956415857588, 0.6294962338038853, 0.6364977972848075, 0.6082184570176261, 0.6203284672328404, 0.599619402204241, 0.6032151682036263, 0.6561343738010952, 0.6849281566483634, 0.6526734403201512, 0.6581192203930446, 0.6017195991107396, 0.5806917531149728, 0.5834471021379743, 0.571040506022317, 0.5568337389401027, 0.565265394960131, 0.5364427702767508, 0.5348128063338143, 0.5186510920524597, 0.5099877383027758, 0.5052023342677525, 0.5229891376835959, 0.4933444559574127, 0.4915455945900508, 0.48411714690072194, 0.4762259159769331, 0.4730114076818739, 0.4929802553994315, 0.4450753952775683, 0.44614524500710623, 0.45513471279825485, 0.44312910437583924, 0.43618321333612714, 0.4241961351462773, 0.4206524278436388, 0.4313933483191899, 0.4055021592548915, 0.407310574395316, 0.4059188323361533, 0.3894360329423632, 0.38478859407561167, 0.39473517622266496, 0.3787152128560202, 0.38671402846063885, 0.3647110019411359, 0.3701643569128854, 0.3550635806151799, 0.36865540146827697, 0.3406182774475643, 0.3523101304258619, 0.3350513185773577, 0.3371124804019928, 0.34212532298905507, 0.3358198813029698, 0.3184084960392543, 0.32871709976877483, 0.3091897657939366, 0.3047153787953513, 0.30807430488722665, 0.3100393831729889, 0.3047399035521916, 0.2925851217338017, 0.30715763654027667, 0.29204375403267996, 0.2838120085852487, 0.2758878495012011, 0.2811949270112174, 0.26815611336912426, 0.2740294077566692, 0.26458112512316023, 0.26510052936417716, 0.2596884250640869, 0.2652879038027355, 0.26514795081956044, 0.24485340075833456, 0.23974404845918929, 0.24829969193254198, 0.23496101583753312, 0.24555872082710267, 0.2505666060107095, 0.23076413231236595, 0.22829094444002423, 0.2303693494626454, 0.21969554764883858, 0.22520012642656054, 0.22216049134731292, 0.21867210566997528, 0.21567712894507818, 0.2104593826191766, 0.2094471492937633, 0.20686771401337214, 0.20509532136576517, 0.205052416239466, 0.2033278635569981, 0.18975830376148223, 0.1931311194385801, 0.1958110294171742, 0.19569242341177803, 0.18634134914193834, 0.1837364843913487, 0.1891445291893823, 0.18496193758078983, 0.17381598140512194, 0.18094944655895234, 0.1741167047194072, 0.1769156698669706, 0.17634939125605992, 0.17551400363445283, 0.16840009306158338, 0.1592171720096043, 0.16349432851587023, 0.16335904896259307, 0.15678754832063402, 0.1616276136466435, 0.15678048176424844, 0.15765049414975302, 0.1555409265416009, 0.14920022870813096, 0.1622454868895667, 0.1505612484046391, 0.14596444836684636, 0.1493209468466895, 0.14251502582005093, 0.1440307834318706, 0.1479300924709865, 0.13278789009366718, 0.14503107198647092, 0.14408398142882756, 0.16217940407139914, 0.12844227573701314, 0.124343327326434, 0.13221871427127294, 0.14306060586656844, 0.15920545714242118, 0.12300982815878732, 0.12060382557766779, 0.12007655224629811, 0.1259224717106138, 0.12239474015576499, 0.13117872497865132, 0.13603432710681643, 0.11788040569850376, 0.12673524788447788, 0.11908451169729233, 0.11474489505801883, 0.12723631603377206, 0.12576564571687154, 0.10870325182165419, 0.11851452950920377, 0.11185441187449864, 0.12961475423404148, 0.11239628621510096, 0.11252753308841161, 0.10654654588018145, 0.11497832366398403, 0.10874604731798172, 0.10562478793518884, 0.11054908377783638, 0.11864887369530541, 0.10563357067959649, 0.10508608115570886, 0.10287429371050426, 0.10471032921757017, 0.10858535255704607, 0.10078432070357458, 0.10460485411541802, 0.09740041749817985, 0.10015412334884916, 0.10845061881201608, 0.10220981666019985, 0.09676452853849955, 0.0980520493217877, 0.09500215883765901, 0.1040170309799058, 0.09711331278085708, 0.10925721121685845, 0.09190476962498256, 0.0960304292184966, 0.08778392097779683, 0.1018749733056341, 0.09601561171667916, 0.09509277067014149, 0.08968688398599625, 0.09163801670074463, 0.09131448460476739, 0.09294988683291844, 0.09039302659886224, 0.09041001094239098, 0.08643087042229516, 0.08690430862562996, 0.0909011619431632, 0.09704833562885012, 0.08222192589725767, 0.0898308983870915, 0.08673126122781209, 0.08902594872883388, 0.07883935123682022, 0.10305072260754448, 0.08537341845887048, 0.0810812594635146, 0.08167110404797963, 0.08757585329668863, 0.0775357180408069, 0.08659139083964484, 0.08853250678096498, 0.08397385797330312, 0.08020266996962684, 0.08127647319010325, 0.08065673687628337, 0.07560091125113623, 0.08633076101541519, 0.088216375878879, 0.07771057529108864, 0.07613143984760556, 0.07910148416246687, 0.07301148069756372, 0.0783904328942299, 0.08510495594569616, 0.07816801433052335, 0.08527934231928416, 0.07846757918596267, 0.07331908409084592, 0.07792778675045287, 0.07616002453225, 0.07846897904361998, 0.07159248909779957, 0.07995533112968717, 0.07101953221218926, 0.08391978974853243, 0.07421909400394984, 0.07321873222078595, 0.07682112221206938, 0.06904269691024507, 0.07935348387275423, 0.07668122202157975, 0.07824945258242744, 0.07180974313191005, 0.06924090534448624, 0.0721217651452337, 0.06989515806947436, 0.07111089250871114, 0.07122282577412468, 0.06600454130343028, 0.08143382923943655, 0.06484075507947377, 0.06536166327340262, 0.07536231790270125, 0.06641120591333934, 0.0794015286224229, 0.06528158273015704, 0.0639639247741018, 0.07372736100639615, 0.06218750679067203, 0.07939826079777308, 0.06357260836022241, 0.0690827129142625, 0.06837393407310759, 0.064577388550554, 0.07029550075531006, 0.06757687479257583, 0.07096565727676664, 0.06343235118048532, 0.06853936463594437, 0.07189206842865263, 0.07034887394734791, 0.09514441138931683, 0.06002937970416886, 0.057845319168908255, 0.0676262223294803, 0.06445274321096284, 0.0596150985785893, 0.06455841000591006, 0.06768243749226843, 0.06754865327051708, 0.06474473817007882, 0.05935206658073834, 0.059404727603708, 0.06957943184035165, 0.061097993275948934, 0.06490277892776898, 0.06145118730408805, 0.07641830252749579, 0.07088353601949555, 0.06413904641355787, 0.05882065051368305, 0.05511209102613585, 0.05913219047444207, 0.06722036004066467, 0.05492282807826996, 0.0654731667467526, 0.06590109733598573, 0.05710907855204173, 0.06216801309159824, 0.05436090944068772, 0.06699870654514857, 0.05821752622723579, 0.05828509735209601, 0.06520782868777003, 0.059361503060374944, 0.06125528046063015, 0.055858710833958214, 0.06184321897370475, 0.05584579301731927, 0.07170777789184025, 0.05962093823722431, 0.055909628527505056, 0.05702327968818801, 0.05463644957968167, 0.05964281825082643, 0.05908094314592225, 0.054589635133743285, 0.06034457853862218, 0.055644911101886206, 0.05523256031530244, 0.05279267845409257, 0.06260430983134678, 0.052286346363169804, 0.0528390112732138, 0.0556832315666335, 0.08358030212777001, 0.05431335323623249, 0.04703422603862626, 0.06512284374662808, 0.050291333986180166, 0.04938180648854801, 0.05798309008990015, 0.05551623542393957, 0.04819263049534389, 0.05259754551308496, 0.060070522448846274, 0.05123858398624829, 0.04871797593576568, 0.061979580777032035, 0.05078534994806562, 0.05066722131201199, 0.050490207331521174, 0.06517900579742023, 0.06326547861099244, 0.04991107199873243, 0.053112860023975375, 0.05282224587031773, 0.04605039262345859, 0.049983362214905874, 0.05830769081200872, 0.04639776423573494, 0.04820278414658138, 0.061393362496580395, 0.04885088790740286, 0.04508144653269223, 0.057624890016657965, 0.04960591888853482, 0.04744053738457816, 0.05940648519567081, 0.04812583848834038, 0.05163652928812163, 0.04984621075647218, 0.04838464590055602, 0.05512325944645064, 0.04531020436968122, 0.05187393001147679, 0.045789800797189986, 0.051308317482471465, 0.04974436919604029, 0.043757944447653636, 0.05231363677552768, 0.052672819580350604, 0.04788139888218471, 0.06275069639086724, 0.0453109652868339, 0.04725626526134355, 0.041781479226691384, 0.05655509542141642, 0.04167539711509432, 0.04590672690953527, 0.04699631365282195, 0.050532153780971256, 0.04267535177724702, 0.0599037766456604, 0.04566472268530301, 0.04025256729551724, 0.05170897160257612, 0.04709071900163378, 0.06307164973446301, 0.04611223180379186, 0.0415958152285644, 0.05078076454145568, 0.04426497657384191, 0.03989357597061566, 0.048511454250131335, 0.04718010159475463, 0.04639683365821838, 0.041054014542273115, 0.05665043177349227, 0.04084149822592735, 0.039375266113451546, 0.0514536871441773, 0.0429450552378382, 0.04009219631552696, 0.039879075224910465, 0.06085179118173463, 0.047502697259187696, 0.04007283395954541, 0.03754279783793858, 0.05694940249834742, 0.04542794738497053, 0.03918951164398875, 0.04416176751255989, 0.04177015210900988, 0.04001319536140987, 0.039608040984187805, 0.053851744106837685, 0.03757862757359232, 0.03855584423456873, 0.03940041320664542, 0.05810504289610045, 0.05118454790541104, 0.03938693755439349, 0.04424242111189025, 0.03916902637907437, 0.03331906848720142, 0.039698361179658345, 0.04596829935908318, 0.043691514432430266, 0.035593739258391516, 0.03505332555089678, 0.06639464625290462, 0.03995017824428422, 0.035163558700254983, 0.034669776473726543, 0.035618299778018676, 0.05889104817594801, 0.03587142410022872, 0.038589013580765046, 0.03709738094891821, 0.042374888913972036, 0.04036944934300014, 0.03349474402410643, 0.04272218963929585, 0.04728704765439033, 0.03490350331578936, 0.035263441715921676, 0.04164527314049857, 0.03513917199202946, 0.04592704772949219, 0.035760845350367686, 0.036245175663914, 0.04917206349117415, 0.03668970220855304, 0.043869592888014654, 0.033998422218220574, 0.039576199225017004, 0.033447676790612085, 0.04602712914347649, 0.03619206771254539, 0.031060040848595757, 0.045681318534272056, 0.0404283059494836, 0.031186735736472265, 0.03278603032231331, 0.045089140960148405, 0.03206452078052929, 0.032683002203702925, 0.04789892360568047, 0.048693461822611944, 0.03162048065236637, 0.032683312413947924, 0.03341979714376586, 0.03803117764847619, 0.03471098616719246, 0.033495432883501056, 0.032611910360200065, 0.0365690963608878, 0.032071599257843836, 0.04885034933686257, 0.03329275734722614, 0.02888521376465048, 0.02857625718627657, 0.049862416407891685, 0.03902267717889377, 0.03771880950246539, 0.032763411690081866, 0.029950805114848274, 0.043227047686065945, 0.042123803602797646, 0.030592935319457736, 0.030921386501618794, 0.041053449681827, 0.03470902730311666, 0.038782301438706264, 0.029807576164603233, 0.04379568610872541, 0.03228242402630193, 0.028606679663062094, 0.04359902750168528, 0.03186919018626213, 0.028569504192897253, 0.027548626278127944, 0.045511945762804575, 0.03480134696832725, 0.028028883838227818, 0.030131525333438602, 0.046517764244760784, 0.03064286836556026, 0.03894178867340088, 0.027265302251492228, 0.03207904978522232, 0.044776478303330286, 0.029295792803168297, 0.028992183612925666, 0.025791395562035697, 0.04300612764699119, 0.032842908054590225, 0.02785801004086222, 0.027103941089340618, 0.04306326476590974, 0.028940334437148912, 0.027454998024872373, 0.03154008931347302, 0.035040912085345814, 0.025794473343661854, 0.04070320480636188, 0.03292416222393513, 0.025238392342414175, 0.026967111974954605, 0.036316245155675074, 0.03677209998880114, 0.02649812081030437, 0.024276779325945037, 0.02504157381398337, 0.05062111584203584, 0.03915247784129211, 0.025650872449789728, 0.023553782062871117, 0.03682708271912166, 0.0293396349464144, 0.025417485034891538, 0.023385851670588764, 0.03758571733321462, 0.030786208223019328, 0.024890625530055593, 0.03602481686643192, 0.029274873062968255, 0.03481491415628365, 0.023572524903076035, 0.022869538781898364, 0.03466709511620658, 0.03802100760596139, 0.027810241441641535, 0.0282455923301833, 0.02291375318808215, 0.0381119929254055, 0.02648980064051492, 0.022869705302374702, 0.02309656393315111, 0.0296862960926124, 0.04227340998394149, 0.02939008426453386, 0.024771220982074738, 0.023567989308919225, 0.03766122417790549, 0.03356800632817405, 0.024262332916259767, 0.02306910455226898, 0.023007801600864956, 0.04775088759405272, 0.026059435307979585, 0.0273758270910808, 0.02377041791166578, 0.026795556609119687, 0.038017095306089946, 0.024994484920586858, 0.02283952704497746, 0.023304676849927222, 0.04399115533701011, 0.024982831307819912, 0.022109091760856764, 0.025435560888477735, 0.03490285234791892, 0.039291818759271076, 0.02345771709723132, 0.021434429500784193, 0.021159325965813228, 0.025000194566590445, 0.030142201696123395, 0.02897770894425256, 0.034195387842399734, 0.023170000314712523, 0.02330037701342787, 0.03735298626124859, 0.025667576332177436, 0.02099909053317138, 0.02090990591262068, 0.021234468689986637, 0.045892238723380226, 0.02750600485929421, 0.021776441165379117, 0.022127634712627957, 0.024573442446334023, 0.034801481025559564, 0.02293312842292445, 0.02475429299686636, 0.04103036549474512, 0.02652799311493124, 0.02160715822662626, 0.021217209420033863, 0.023476754873991014, 0.03707821709769113, 0.022465900384954045, 0.021119196606533868, 0.021062835199492317, 0.02142351871090276, 0.03300065036330904, 0.039534095781190055, 0.02303786240518093, 0.024652101897767613, 0.022708533225314957, 0.021279561200312207, 0.03542492352426052, 0.0220675845763513, 0.02028118393250874, 0.020167598607284683, 0.020425411207335337, 0.02883934091244425, 0.03547721233751092, 0.029951158751334462, 0.021221996045538358, 0.02069791347852775, 0.025334561190434864, 0.04423351772129536, 0.025658159170831953, 0.020737594791821072, 0.020132771613342423, 0.019954669528773852, 0.030502668342420033, 0.026844944272722517, 0.021177445618169647, 0.021717143750616483, 0.019883126499397413, 0.022687397631151334, 0.03854694047144481, 0.021393065952828954, 0.02102800261761461, 0.02093016148677894, 0.02470012828707695, 0.03332693837583065, 0.020612429933888572, 0.020945227199367113, 0.023373386902468544, 0.03238252348133496, 0.028065317922404836, 0.01981155164539814, 0.01923144156379359, 0.03150549775787762, 0.0270714848701443, 0.019622893152492386, 0.019293973967432976, 0.020711062529257366, 0.03914810631956373, 0.027467987739614078, 0.01965586239738124, 0.020144138112664224, 0.01955202908388206, 0.020728995172040802, 0.026429295539855957, 0.029535771746720587, 0.020231243329388755, 0.022745118343404362, 0.020323434312428747, 0.03488872519561222, 0.026943866057055336, 0.019225472318274633, 0.01942965766148908, 0.01927256797041212, 0.03620621902602059, 0.023708519499216762, 0.019847314698355538, 0.01945441450391497, 0.025035733942474638, 0.027765625662037306, 0.01902479976415634, 0.018849697123680797, 0.01889708164547171, 0.02345873787999153, 0.036286373436450955, 0.019777103566697665, 0.01959429771772453, 0.018865913418786868, 0.0212019894272089, 0.037835648017270226, 0.019960731241319862, 0.018546299050961224, 0.01959988559995379, 0.019244326438222614, 0.01957659354167325, 0.040542904234358246, 0.021499864597405705, 0.018952361547521182, 0.01890388381268297, 0.01863431754921164, 0.019086104205676486, 0.019357211302433695, 0.041593459833945544, 0.020709339582494327, 0.01992160842886993, 0.01918608546257019, 0.02046950879905905, 0.022748349394117084, 0.038076706656387876, 0.02046542896756104, 0.01801810802093574, 0.023244085162878035, 0.019526863523891994, 0.018016323127916883, 0.018147055857947895, 0.028781408284391675, 0.028785719882164683, 0.018446192571095057, 0.018139757375632014, 0.018011496482150894, 0.018395105696150233, 0.018521025351115637, 0.03124306494636195, 0.02391623386314937, 0.019414632448128293, 0.01927295172853129, 0.021589754734720502, 0.020988845346229416, 0.024086851733071464, 0.02795929264809404, 0.01846586822399071, 0.018446757910507067, 0.018145300394722393, 0.01826661175915173, 0.019038583976881844, 0.021257330530456135, 0.03354492661144052, 0.018920367157885008, 0.01834261156618595, 0.018032907801015036, 0.01909104830452374, 0.019291367860777037, 0.02827856114932469, 0.026930813544562886, 0.02055753751524857, 0.019226103435669627, 0.020707621265734943, 0.019304064395172255, 0.01841194826577391, 0.033817111647554805, 0.01919838237975325, 0.018756979012063572, 0.01790463158062526, 0.017534996409501347, 0.01917050283934389, 0.041331011801958084, 0.02316632041973727, 0.017991896346211435, 0.01743033459143979, 0.01739950217306614, 0.0175631474171366, 0.01803857476583549, 0.023720409934009826, 0.03774401864835194, 0.021410785455788884, 0.0180095517209598, 0.017365050581949096, 0.01764958570046084, 0.017634906460131917, 0.0297976872750691, 0.027894216935549464, 0.020357366225549154, 0.018398461384432657, 0.017679078238351003, 0.017867723905614443, 0.02189332161630903, 0.034643092964376725, 0.030484344916684288, 0.01936406764600958, 0.01748817903654916, 0.017220884189009668, 0.017340021740112985, 0.017163066299898284, 0.017408086838466782, 0.030399462154933384, 0.02308514229953289, 0.019448184594511985, 0.017762976884841918, 0.017399726861289568, 0.017673181263463837, 0.020305644507919038, 0.034566800934927804, 0.019981734028884344, 0.017908580494778496, 0.01746206076017448, 0.017508466807859283, 0.023957419395446777, 0.024106355809739657, 0.017638222766774042, 0.018107120958822113, 0.019157310096280914, 0.01866956294647285, 0.017933583099927222, 0.03128191062382289, 0.021133304493767876, 0.018173401909215108, 0.01926454481269632, 0.017586939835122654, 0.01762265610907759, 0.022742626177413124, 0.04565356969833374, 0.023317119106650352, 0.017747730442455836, 0.01763059523488794, 0.017645684789334024, 0.017891444744808332, 0.03107834378523486, 0.02216986103781632, 0.017989884955542428, 0.017590383120945522, 0.01705471154834543, 0.017838347224252565, 0.017913267495376722, 0.019677436937178883, 0.033782032557896205, 0.02074883095920086, 0.019615346885153224, 0.018620122809495245, 0.0176299052046878, 0.019152989451374326, 0.01799842081964016, 0.025959757821900502, 0.018854445112603053, 0.01690991579421929, 0.017030558841569083, 0.022022253807101932, 0.029561258213860648, 0.018351281487515993, 0.01770353242754936, 0.0180435448884964, 0.01739857904613018, 0.017650496533938815, 0.025881095443453107, 0.020882015515651022, 0.018732665638838495, 0.017807665946228162, 0.017304671662194387, 0.017831977403589657, 0.018264104266251836, 0.0185484554618597, 0.0275226033691849, 0.019417639928204673, 0.023480910062789916, 0.02010594244514193, 0.01880118107157094, 0.017093661427497863, 0.0167171338307006, 0.019102836293833598, 0.02528531003211226, 0.0175054633723838, 0.0170793991535902, 0.017072951314704758, 0.019290091044136457, 0.020894899166056087, 0.02677781576556819, 0.01763120692755495, 0.01747359846319471, 0.016737731492945124, 0.01733576085950647, 0.019621212727257184, 0.020842650639159337, 0.017360771128109524, 0.016871255370123045, 0.02122966434274401, 0.020568342240793364, 0.017059545697910444, 0.017643343657255173, 0.03346241233604295, 0.039437081611582214, 0.021897130725639206, 0.020219387060829572, 0.016984134699617112, 0.016473018058708735, 0.016647839067237716, 0.016804815243397442, 0.016820107347198895, 0.031101537974817413, 0.019823199350919044, 0.017232720074909075, 0.016949267525758063, 0.017972814132060325, 0.017075914623481885, 0.017120706023914474, 0.0181493129581213, 0.024475357042891638, 0.02426656394132546, 0.019184531484331403, 0.01672012566455773, 0.016164278185793333, 0.0163791687893016, 0.016381235952888217, 0.01907420131777014, 0.03360244482755661, 0.01724923253059387, 0.01641194527702672, 0.016740351436393602, 0.01681084930896759, 0.016904566756316592, 0.02317777701786586, 0.031564629530268055, 0.01702322619301932, 0.016413890197873114, 0.016079754116279737, 0.016389850207737516, 0.01674388482102326, 0.01920735165476799, 0.01882636621594429, 0.021176765273724283, 0.02471215051731893, 0.017511491530707905, 0.016531859391501973, 0.016333796456456183, 0.0164892118158085, 0.017868209364158765, 0.02608950888471944, 0.017694920301437378, 0.016653069853782655, 0.0168659547077758, 0.01678924448788166, 0.01687139299299036, 0.03057855660361903, 0.022147801890969276, 0.016750769317150117, 0.01644720464412655, 0.016184339778763907, 0.016433576068707875, 0.02440029393349375, 0.020287533743040903, 0.01656201524393899, 0.017145878715174537, 0.016371935765658107, 0.016940389573574067, 0.017387145491583007, 0.017989386139171466]}\n"
     ]
    }
   ],
   "source": [
    "print (history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: What child is this, who, laid to rest\n",
      "B | \"F\"c2 A | A>^G A | \"E\"B2 ^G | E\n",
      "w: On Mary's lap is sleeping\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2B | \"Em\"G>\n",
      "w: Whom angels greet with anthems sweet\n",
      "\"Em\"G>A B | \"F\"c>B A | \"E7\"^G>F G | \"Am\"A3 | A3 \n",
      "w: While shepherds watch are keeping?\n",
      "\"C\"g3 | g>f e | \"Bm\"d2 B | \"Em\"G>\n",
      "w: This, this is Christ the King\n",
      "B | \"Am\"c2 A | \"F\"A>^G A | \"E\"B2 ^G | E3 \n",
      "w: Whom shepherds guard and angels sing\n",
      "\"C\"g3 | g>f e | \"Bm\"d2 B | \"Em\"G>\n",
      "w: This, this is Christ the King\n",
      "\"Em\"G>A B | \"F\"c>B A | \"E7\"^G>F G | \"Am\"A3 | A2 |\n",
      "w: The Babe, the Son of Mary.\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: Why lies He in such mean estate\n",
      "\"Em\"G>A B | \"F\"c2 A | A>^G A | \"E\"B2 ^G \n",
      "w: Where ox and ass are feeding?\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: Good Christian, fear, for sinners here\n",
      "\"Em\"G>A B | \"F\"c>B A | \"E7\"^G>F G | \"Am\"A3 | A3 \n",
      "w: The silent Word is pleading.\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: So bring Him incense, gold and myrrh\n",
      "B | \"F\"c2 A | A>^G A | \"E\"B2 ^G | E\n",
      "w: Come, peasant, King to own Him\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: The King of Kings salvation brings\n",
      "\"Em\"G>A B | \"F\"c>B A | \"E7\"^G>F G | \"Am\"A3 | A3 \n",
      "w: Let loving hearts enthrone him.\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: This, this is Christ the King,\n",
      "B | \"F\"c2 A | A>^G A | \"E\"B2 ^G | E\n",
      "w: Whom shepherds guard and angels sing.\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: This, this is Christ the King,\n",
      "\"Em\"G>A B | \"F\"c>B A | \"E7\"^G>F G | \"Am\"A3 | A2 |\n",
      "w: The Babe, the Son of Mary.\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: What child is this, who, laid to rest,\n",
      "\"Em\"G>A B | \"F\"c2 A | A>^G A | \"E\"B2 ^G \n",
      "w: On Mary's lap is sleeping?\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2B | \"Em\"G>\n",
      "w: Whom angels greet with anthems sweet\n",
      "\"Em\"G>A B | \"F\"c>B A | \"E7\"^G>F G | \"Am\"A3 | A3 \n",
      "w: While shepherds watch are keeping?\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: This, this is Christ the King,\n",
      "B | \"F\"c2 A | A>^G A | \"E\"B2 ^G | E\n",
      "w: Whom shepherds guard and angels sing.\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: This, this is Christ the King,\n",
      "\"Em\"G>A B | \"F\"c>B A | \"E7\"^G>F G | \"Am\"A3 | A2 |\n",
      "w: The Babe, the Son of Mary.\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: Why lies He in such mean estate\n",
      "\"Em\"G>A B | \"F\"c2 A | A>^G A | \"E\"B2 ^G \n",
      "w: Where ox and ass are feeding?\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: Good Christian, fear, for sinners here\n",
      "\"Em\"G>A B | \"F\"c>B A | \"E7\"^G>F G | \"Am\"A3 | A3 \n",
      "w: The silent Word is pleading.\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: So bring Him incense, gold and myrrh\n",
      "\"Em\"G>A B | \"F\"c2 A | A>^G A | \"E\"B2 ^G \n",
      "w: Come, peasant, King to own Him;\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: The King of Kings salvation brings\n",
      "\"Em\"G>A B | \"F\"c>B A | \"E7\"^G>F G | \"Am\"A3 | A3 \n",
      "w: Let loving hearts enthrone him.\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: What child is this, who, laid to rest,\n",
      "\"Em\"G>A B | \"F\"c2 A | A>^G A | \"E\"B2 ^G \n",
      "w: On Mary's lap is sleeping?\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2B | \"Em\"G>\n",
      "w: Whom angels greet with anthems sweet\n",
      "\"Em\"G>A B | \"F\"c>B A | \"E7\"^G>F G | \"Am\"A3 | A3 \n",
      "w: While shepherds watch are keeping?\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: This, this is Christ the King,\n",
      "B | \"F\"c2 A | A>^G A | \"E\"B2 ^G | E\n",
      "w: Whom shepherds guard and angels sing.\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: This, this is Christ the King,\n",
      "\"Em\"G>A B | \"F\"c>B A | \"E7\"^G>F G | \"Am\"A3 | A2 |\n",
      "w: The Babe, the Son of Mary.\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: Why lies He in such mean estate\n",
      "\"Em\"G>A B | \"F\"c2 A | A>^G A | \"E\"B2 ^G \n",
      "w: Where ox and ass are feeding?\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: Good Christian, fear, for sinners here\n",
      "\"Em\"G>A B | \"F\"c>B A | \"E7\"^G>F G | \"Am\"A3 | A3 \n",
      "w: The silent Word is pleading.\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: So bring Him incense, gold and myrrh\n",
      "\"Em\"G>A B | \"F\"c2 A | A>^G A | \"E\"B2 ^G \n",
      "w: Come, peasant, King to own Him;\n",
      "A | \"Am\"c2 d | \"D7\"e>f e | \"G\"d2 B | \"Em\"G>\n",
      "w: The King of Kings salvation brings\n",
      "\"Em\"G>A B | \"F\"c>B A | \"E7\"^G>F G | \"Am\"A3 | A3 \n",
      "w: Let loving hearts enthrone him.\n",
      "B2 A | G3 B2 A | G3- G2 F | E2 F G2 E | D3- D\n",
      "w: Well it's all for me grog, me jolly, jolly grog.\n",
      "A | B3 B2 c | d3 c2 B | B A2- A3- | A\n",
      "w: It's all for me beer and tobacco,\n",
      "B2 c | d3 d2 B | G3 G2 F | E2 F G2 E | D\n",
      "w: For I spent all me tin on the lassies drinking gin,\n",
      "B2 B | B2 d d2 d | d2 B G2 B | (A6 | G3) |\n",
      "w: Far across the western ocean I must wander.\n",
      "G3 B2 A | G3- G2 F | E2 F G2 E | D3- D\n",
      "w: Where are me boots, me noggin', noggin' boots?\n",
      "B | B3 d2 d | d3 c2 B | B A2- A3- | A\n",
      "w: They're all gone for beer and tobacco,\n",
      "B2 c | d2 d B2 A | G3 F2 G | A2 G F2 E | D\n",
      "w: For the heels they are worn out and the toes are kicked about\n",
      "B2 B | B2 d d2 d | d2 B G2 B | (A6 | G3) |\n",
      "w: And the soles are looking out for better weather.\n",
      "G3 B2 A | G3- G2 F | E2 F G2 E | D3- D\n",
      "w: Where is me shirt, me noggin', noggin' shirt?\n",
      "B | B3 d2 d | d3 c2 B | B A2- A3- | A\n",
      "w: It's all gone for beer and tobacco,\n",
      "B2 c | d2 d B2 A | G3 F2 G | A2 G F2 E | D\n",
      "w: For the collar is all worn, and the sleeves they are all torn,\n",
      "B2 B | B2 d d2 d | d2 B G2 B | (A6 | G3) |\n",
      "w: And the tail is looking out for better weather.\n",
      "G3 B2 A | G3- G2 F | E2 F G2 E | D3- D\n",
      "w: I'm sick in the head and I haven't been to bed,\n",
      "B | B3 d2 d | d3 c2 B | B A2- A3- | A\n",
      "w: Since first I came ashore from me slumber,\n",
      "B2 c | d2 d B2 A | G3 F2 G | A2 G F2 E | D\n",
      "w: For I spent all me dough on the lassies don't you know,\n",
      "B2 B | B2 d d2 d | d2 B G2 B | (A6 | G3) |\n",
      "w: Far across the western ocean I must wander.\n",
      "\"C\"G G2 G | c2 d c | e e2 d | c\n",
      "w: I know a place 'bout a mile down the road\n",
      "G G | \"C\"G G2 G | A G E2 | \"G\"D4- | D\n",
      "w: where you lay down a dollar or two.\n",
      "C D | E E2 F | A\n",
      "w: If you hush up your mug,\n",
      "G F | A A2 G | F\n",
      "w: they will slip you a jug\n",
      "d c | e g3 | c2 \"G7\"d2 | \"C\"c4- | c4 |\n",
      "w: of that good old mountain dew.\n",
      "G | D D2 D | E2 G A | (B2 d2 | \"G7\"=f3\n",
      "w: They call it that old mountain dew,\n",
      "G | \"Bb\"F F2 F | G F D2 | \"F\"C4- | C\n",
      "w: and them that refuse it are few.\n",
      "C D | E E2 F | A\n",
      "w: You may go 'round the bend\n",
      "G F | A c2 A | F\n",
      "w: but you'll come back a-gain\n",
      "G F | A c3 | F2 \"C7\"G2 | \"F\"F4- | F4 |\n",
      "w: for that good old mountain dew.\n",
      "\"C\"G G2 G | c2 d c | e e2 d | c\n",
      "w: I know a place 'bout a mile down the road\n",
      "G G | \"C\"G G2 G | A G E2 | \"G\"D4- | D\n",
      "w: where you lay down a dollar or two.\n",
      "C D | E E2 F | A\n",
      "w: If you hush up your mug,\n",
      "G F | A A2 G | F\n",
      "w: they will slip you a jug\n",
      "d c | e g3 | c2 \"G7\"d2 | \"C\"c4- | c4 |\n",
      "w: of that good old mountain dew.\n",
      "G | D D2 D | E2 G A | (B2 d2 | \"G7\"=f3\n",
      "w: They call it that old mountain dew,\n",
      "G | \"Bb\"F F2 F | G F D2 | \"F\"C4- | C\n",
      "w: and them that refuse it are few.\n",
      "C D | E E2 F | A\n",
      "w: You may go 'round the bend\n",
      "G F | A c2 A | F\n",
      "w: but you'll come back a-gain\n",
      "G F | A c3 | F2 \"C7\"G2 | \"F\"F4- | F4 |\n",
      "w: for that good old mountain dew.\n",
      "\"C\"G G2 G | c2 d c | e e2 d | c\n",
      "w: I know a place 'bout a mile down the road\n",
      "G G | \"C\"G G2 G | A G E2 | \"G\"D4- | D\n",
      "w: where you lay down a dollar or two.\n",
      "C D | E E2 F | A\n",
      "w: If you hush up your mug,\n",
      "G F | A A2 G | F\n",
      "w: they will slip you a jug\n",
      "d c | e g3 | c2 \"G7\"d2 | \"C\"c4- | c4 |\n",
      "w: of that good old mountain dew.\n",
      "G | D D2 D | E2 G A | (B2 d2 | \"G7\"=f3\n",
      "w: They call it that old mountain dew,\n",
      "G | \"Bb\"F F2 F | G F D2 | \"F\"C4- | C\n",
      "w: and them that refuse it are few.\n",
      "C D | E E2 F | A\n",
      "w: You may go 'round the bend\n",
      "G F | A c2 A | F\n",
      "w: but you'll come back a-gain\n",
      "G F | A c3 | F2 \"C7\"G2 | \"F\"F4- | F4 |\n",
      "w: for that good old mountain dew.\n",
      "\"C\"G G2 G | c2 d c | e e2 d | c\n",
      "w: I know a place 'bout a mile down the road\n",
      "G G | \"C\"G G2 G | A G E2 | \"G\"D4- | D\n",
      "w: where you lay down a dollar or two.\n",
      "C D | E E2 F | A\n",
      "w: If you hush up your mug,\n",
      "G F | A A2 G | F\n",
      "w: they will slip you a jug\n",
      "d c | e g3 | c2 \"G7\"d2 | \"C\"c4- | c4 |\n",
      "w: of that good old mountain dew.\n",
      "G | D D2 D | E2 G A | (B2 d2 | \"G7\"=f3\n",
      "w: They call it that old mountain dew,\n",
      "G | \"Bb\"F F2 F | G F D2 | \"F\"C4- | C\n",
      "w: and them that refuse it are few.\n",
      "C D | E E2 F | A\n",
      "w: You may go 'round the bend\n",
      "G F | A c2 A | F\n",
      "w: but you'll come back a-gain\n",
      "G F | A c3 | F2 \"C7\"G2 | \"F\"F4- | F4 |\n",
      "w: for that good old mountain dew.\n",
      "D2 | G4 (3(BAG) | B4 BA | G4 E2 | D\n",
      "w: Amazing grace, how sweet the sound\n",
      "D2 | G4 (3(BAG) | B4 AB | d6- | d\n",
      "w: That saved a wretch like me.\n",
      "Bd | d4 (3(BAG) | B4 BA | G4 E2 | D\n",
      "w: I once was lost, but now am found,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D2 | G4 (3(BAG) | B4 BA | G6- | G4 |\n",
      "w: Was blind, but now I see.\n",
      "D2 | G4 (3(BAG) | B4 BA | G4 E2 | D\n",
      "w: Amazing grace, how sweet the sound\n",
      "D2 | G4 (3(BAG) | B4 AB | d6- | d\n",
      "w: That saved a wretch like me.\n",
      "Bd | d4 (3(BAG) | B4 BA | G4 E2 | D\n",
      "w: I once was lost, but now am found,\n",
      "D2 | G4 (3(BAG) | B4 BA | G6- | G4 |\n",
      "w: Was blind, but now I see.\n",
      "G | \"C\"G2 A | (c d) e | \"F\"c2 c | (\"C\"A G\n",
      "w: My latest sun is sinking fast.\n",
      "G | c2 d | \"G\"e2 d | \"C\"c3 | z\n",
      "w: My race is nearly run.\n",
      "C | C2 C | (F G A) | \"Bb\"F2 F | (\"F\"F C\n",
      "w: My strongest trials now are past.\n",
      "G | c2 d | \"G\"e2 d | \"C\"c3 | z3 |\n",
      "w: My triumph has begun.\n",
      "\"A\"e3 | e3 | \"D\"f2 e | d3 \n",
      "w: O, come, Angel Band.\n",
      "\"G\"d3 | d2 c | \"C\"e2 d | c\n",
      "w: Come and around me stand.\n",
      "d | \"G\"B d d | e d B | \"D\"A2 B | d\n",
      "w: O, bear me away on your snow white wings\n",
      "G | G2 G | \"D\"B2 A | \"G\"G3 |\n",
      "w: to my immortal home.\n",
      "d | \"G\"B d d | e d B | \"D\"A2 B | d\n",
      "w: O, bear me away on your snow white wings\n",
      "G | G2 G | \"D\"B2 A | \"G\"G3 |\n",
      "w: to my immortal home.\n",
      "G | \"C\"G2 A | (c d) e | \"F\"c2 c | (\"C\"A G\n",
      "w: My latest sun is sinking fast.\n",
      "G | c2 d | \"G\"e2 d | \"C\"c3 | z\n",
      "w: My race is nearly run.\n",
      "C | C2 C | (F G A) | \"Bb\"F2 F | (\"F\"F C\n",
      "w: My strongest trials now are past.\n",
      "G | c2 d | \"G\"e2 d | \"C\"c3 | z3 |\n",
      "w: My triumph has begun.\n",
      "\"A\"e3 | e3 | \"D\"f2 e | d3 \n",
      "w: O, come, Angel Band.\n",
      "\"G\"d3 | d2 c | \"C\"e2 d | c\n",
      "w: Come and around me stand.\n",
      "d | \"G\"B d d | e d B | \"D\"A2 B | d\n",
      "w: O, bear me away on your snow white wings\n",
      "G | G2 G | \"D\"B2 A | \"G\"G3 |\n",
      "w: to my immortal home.\n",
      "d | \"G\"B d d | e d B | \"D\"A2 B | d\n",
      "w: O, bear me away on your snow white wings\n",
      "G | G2 G | \"D\"B2 A | \"G\"G3 |\n",
      "w: to my immortal home.\n",
      "G | \"C\"G2 A | (c d) e | \"F\"c2 c | (\"C\"A G\n",
      "w: My latest sun is sinking fast.\n",
      "G | c2 d | \"G\"e2 d | \"C\"c3 | z\n",
      "w: My race is nearly run.\n",
      "C | C2 C | (F G A) | \"Bb\"F2 F | (\"F\"F C\n",
      "w: My strongest trials now are past.\n",
      "G | c2 d | \"G\"e2 d | \"C\"c3 | z3 |\n",
      "w: My triumph has begun.\n",
      "\"A\"e3 | e3 | \"D\"f2 e | d3 \n",
      "w: O, come, Angel Band.\n",
      "\"G\"d3 | d2 c | \"C\"e2 d | c\n",
      "w: Come and around me stand.\n",
      "d | \"G\"B d d | e d B | \"D\"A2 B | d\n",
      "w: O, bear me away on your snow white wings\n",
      "G | G2 G | \"D\"B2 A | \"G\"G3 |\n",
      "w: to my immortal home.\n",
      "d | \"G\"B d d | e d B | \"D\"A2 B | d\n",
      "w: O, bear me away on your snow white wings\n",
      "G | G2 G | \"D\"B2 A | \"G\"G3 |\n",
      "w: to my immortal home.\n",
      "G | \"C\"G2 A | (c d) e | \"F\"c2 c | (\"C\"A G\n",
      "w: My latest sun is sinking fast.\n",
      "G | c2 d | \"G\"e2 d | \"C\"c3 | z\n",
      "w: My race is nearly run.\n",
      "C | C2 C | (F G A) | \"Bb\"F2 F | (\"F\"F C\n",
      "w: My strongest trials now are past.\n",
      "G | c2 d | \"G\"e2 d | \"C\"c3 | z3 |\n",
      "w: My triumph has begun.\n",
      "\"A\"e3 | e3 | \"D\"f2 e | d3 \n",
      "w: O, come, Angel Band.\n",
      "\"G\"d3 | d2 c | \"C\"e2 d | c\n",
      "w: Come and around me stand.\n",
      "d | \"G\"B d d | e d B | \"D\"A2 B | d\n",
      "w: O, bear me away on your snow white wings\n",
      "G | G2 G | \"D\"B2 A | \"G\"G3 |\n",
      "w: to my immortal home.\n",
      "d | \"G\"B d d | e d B | \"D\"A2 B | d\n",
      "w: O, bear me away on your snow white wings\n",
      "G | G2 G | \"D\"B2 A | \"G\"G3 |\n",
      "w: to my immortal home.\n",
      "e | f2 ff f2 ed | efed B2 \n",
      "w: In eighteen and four-teen we took a little trip,\n",
      "G | AAAB AGED | GGGG D2 \n",
      "w: Along with Colonel Jackson down the mighty Mississip.\n",
      "D | BBBc BBAG | ABAG E\n",
      "w: We took a little bacon, and we took a little beans,\n",
      "GG | AGAB AGED | GG GG G2 \n",
      "w: and we fought the bloody British in the town of New Orleans.\n",
      "d | f2 a2 a2 fg | abaf ed \n",
      "w: We fired our guns and the British kept a'comin'.\n",
      "d | ffaa afab | afee d2 \n",
      "w: There wasn't 'bout as many as there was a while ago.\n",
      "B | d2 d2 d2 B2 | dedB AG- G2 \n",
      "w: We fired once more, and they began to runnin'\n",
      "dBde ddde | dB AG G2 z |\n",
      "w: Down the Mississipi to the Gulf of Mexico.\n",
      "e | f2 ff f2 ed | efed B2 \n",
      "w: In eighteen and four-teen we took a little trip,\n",
      "G | AAAB AGED | GGGG D2 \n",
      "w: Along with Colonel Jackson down the mighty Mississip.\n",
      "D | BBBc BBAG | ABAG E\n",
      "w: We took a little bacon, and we took a little beans,\n",
      "GG | AGAB AGED | GG GG G2 \n",
      "w: and we fought the bloody British in the town of New Orleans.\n",
      "d | f2 a2 a2 fg | abaf ed \n",
      "w: We fired our guns and the British kept a'comin'.\n",
      "d | ffaa afab | afee d2 \n",
      "w: There wasn't 'bout as many as there was a while ago.\n",
      "B | d2 d2 d2 B2 | dedB AG- G2 \n",
      "w: We fired once more, and they began to runnin'\n",
      "dBde ddde | dB AG G2 z |\n",
      "w: Down the Mississipi to the Gulf of Mexico.\n",
      "E | \"F\"F F D C | F F D C/2C/2 | F F \"C\"G G | \"F\"A c\n",
      "w: One evening as the sun went down, and the jungle fire was burning,\n",
      "C/2C/2 | F F/2F/2 G G | A F2 C/2C/2 | F F \"C\"G F | \"F\"A c\n",
      "w: Down the track came a hobo hiking, and he said, \"Boys, I'm not turning.\n",
      "c | \"Bb\"d/2d/2 d/2d/2 \"F\"c c | \"Bb\"d d \"F\"c>c | \"Bb\"d c B A | \"C7\"G C2 z/\n",
      "w: I'm headed for a land that's far away beside the crystal fountains.\n",
      "D/2 | \"G\"G G E D | G G E z/2 D/2 | G G \"D7\"A A | \"G\"B G2 |\n",
      "w: So, come with me. Well go and see the Big Rock Candy Mountains.\"\n",
      "B/2A/2 | \"G\"G G G A | B d2 d/2d/2 | \"C\"e e g g | \"G\"d\n",
      "w: In the Big Rock Candy Mountains, there's a land that's fair and bright,\n",
      "d/2d/2 | \"C\"e e g e | \"G\"d B2 B/2B/2 | e d c B | \"D7\"A\n",
      "w: where the hand-outs grow on bushes, and you sleep out ev'ry night,\n",
      "A/2A/2 | \"G\"G G G A | B d2 d/2d/2 | \"C\"e e g g | \"G\"d\n",
      "w: where the boxcars all are empty, and the sun shines ev'ry day\n",
      "d/2d/2 | \"C\"e e/2e/2 \"G\"d d/2d/2 | \"C\"e/2e/2 e \"G\"\n",
      "w: on the birds and the bees and the cigarette trees,\n",
      ">d |\"C\"e e \"G\"d d/2d/2 | \"C\"e e \"G\"\n",
      "w: the lemonade springs where the bluebird sings,\n",
      "A/2B/2 | \"C7\"c c G B | \"F\"A F3 |\n",
      "w: in the Big Rock Candy Mountains.\n",
      "E | \"F\"F F D C | F F D C/2C/2 | F F \"C\"G G | \"F\"A c\n",
      "w: One evening as the sun went down, and the jungle fire was burning,\n",
      "C/2C/2 | F F/2F/2 G G | A F2 C/2C/2 | F F \"C\"G F | \"F\"A c\n",
      "w: Down the track came a hobo hiking, and he said, \"Boys, I'm not turning.\n",
      "c | \"Bb\"d/2d/2 d/2d/2 \"F\"c c | \"Bb\"d d \"F\"c>c | \"Bb\"d c B A | \"C7\"G C2 z/\n",
      "w: I'm headed for a land that's far away beside the crystal fountains.\n",
      "D/2 | \"G\"G G E D | G G E z/2 D/2 | G G \"D7\"A A | \"G\"B G2 |\n",
      "w: So, come with me. Well go and see the Big Rock Candy Mountains.\"\n",
      "B/2A/2 | \"G\"G G G A | B d2 d/2d/2 | \"C\"e e g g | \"G\"d\n",
      "w: In the Big Rock Candy Mountains, there's a land that's fair and bright,\n",
      "d/2d/2 | \"C\"e e g e | \"G\"d B2 B/2B/2 | e d c B | \"D7\"A\n",
      "w: where the hand-outs grow on bushes, and you sleep out ev'ry night,\n",
      "A/2A/2 | \"G\"G G G A | B d2 d/2d/2 | \"C\"e e g g | \"G\"d\n",
      "w: where the boxcars all are empty, and the sun shines ev'ry day\n",
      "d/2d/2 | \"C\"e e/2e/2 \"G\"d d/2d/2 | \"C\"e/2e/2 e \"G\"\n",
      "w: on the birds and the bees and the cigarette trees,\n",
      ">d |\"C\"e e \"G\"d d/2d/2 | \"C\"e e \"G\"\n",
      "w: the lemonade springs where the bluebird sings,\n",
      "A/2B/2 | \"C7\"c c G B | \"F\"A F3 |\n",
      "w: in the Big Rock Candy Mountains.\n",
      "D | B2 B B2 B | c c2 z c | d2 d B2 G | A3-A\n",
      "w: We are a band of brothers, and native to the soil,\n",
      "z | g2 g f2 g | e2 d B2 G | B2 A G2 F | G3-G\n",
      "w: Fighting for the property we gained by honest toil.\n",
      "D | B2 B B2 B | c2 c z c | d2 d B2 G | A3-A\n",
      "w: And, when our rights were threatened, the cry rose near and far,\n",
      "D | B2 B B2 B | c2 c z c | d2 d B2 G | A3-A\n",
      "w: And, when our rights were threatened, the cry rose near and far,\n",
      "d | g3-g2 d | g3-g2 d | e2 e e2 e | d3-d\n",
      "w: Hurrah! Hurrah! For Southern rights, hurrah!\n",
      "d | g3-g2 d | g3-g2 d | e2 e e2 e | d3-d\n",
      "w: Hurrah! Hurrah! For Southern rights, hurrah!\n",
      "\"G\"G G/A/ \"Em\"B G/G/ | \"C\"A G \"D7\"E D | \"G\"G G/A/ \"Bm\"B d/d/ \n",
      "w: I am a weaver, a calton weaver. I am a rash and a\n",
      "\"C\"e e \"D7\"d2 | \"C\"e e \"Em\"d B | \"C\"(c/B/) (A/G/) \"D7\"F D \n",
      "w: roving blade. I've got silver in my pockets.\n",
      "\"G\"G G/A/ \"Em\"B G/B/ | \"C\"A G (\"D7\"E D) |\n",
      "w: I'll go and follow the roving trade.\n",
      "\"G\"G>A \"Em\"B G | \"C\"A G \"D7\"E D | \"Em\"G>A \"Bm\"B d | \"C\"B A \"D7\"G2 |\n",
      "w: Whisky, whisky, Nancy whisky. Whisky, whisky, Nancy, oh.\n",
      "DE|\"G\"G-GG-G|\"G\"EDB,D|\"G\"G4|\"G\"z2 GA\n",
      "w: She'll be coming 'round the mountain when she comes. She'll be\n",
      "\"G\"B-BB-B|\"G\"dBAG|\"D7\"A4|\"D7\"z2 dc\n",
      "w: coming 'round the mountain when she comes. She'll be\n",
      "\"G\"B-BB-B|\"G7\"AGGG|\"C\"E-EE-E|\"C\"AGFE\n",
      "w: coming 'round the mountain, she'll be coming 'round the mountain, she'll be\n",
      "\"G\"D-DD-D|\"D7\"BAFD|\"G\"G4|\"G\"z2|\n",
      "w: coming 'round the mountain when she comes.\n",
      "z2 \"A\"E E | F E3 | z2 \"F#m\"F E | F A3 \n",
      "w: Almost Heaven. West Virginia.\n",
      "z2 \"D\"A A | B A3 | \"C\"E E E D | \"G\"E G3 \n",
      "w: Blue Ridge Mountains. Shennandoah River.\n",
      "z2 C C | D C3 | \"Dm\"D F F A | F4 \n",
      "w: Life is old there, older than the trees,\n",
      "\"C\"G G G G | A G3 | \"Bb\"D F F G | \"F\"F2 |\n",
      "w: younger than the mountains, blowing like the breeze.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A | B4 | z2 B G | \"D\"A4 | z\n",
      "w: Country roads take me home\n",
      "B A | \"Em\"G4 | z2 B d | \"C\"e4 | z\n",
      "w: to the place I belong,\n",
      "e e | \"G\"d B3 | z2 B G | \"D\"A B3 | z\n",
      "w: West Virginia, mountain mama.\n",
      "B A | \"C\"G4 | z2 G A | \"G\"G4 | z4 |\n",
      "w: Take me home, country roads.\n",
      "z \"Dm\"F F F | \"C\"C\n",
      "w: I hear her voice.\n",
      "G A | \"G\"B B B B | B A G2 | \n",
      "w: In the morning hour she calls_ me.\n",
      "\"C\"c c c | \"G\"c B A G | \"D\"A2 B B | A4 \n",
      "w: Radio reminds me of my home far a-way.\n",
      "\"Em\"B B B B | \"F\"A A A A | \"C\"G \n",
      "w: Drivin' down the road I get a feeling\n",
      "A A | \"A\"A A B A | \"E\"B c B2 | z\n",
      "w: that I should have been home yes-ter-day,\n",
      "A B | c4 | z2 |\n",
      "w: Yesterday.\n",
      "z2 \"A\"E E | F E3 | z2 \"F#m\"F E | F A3 \n",
      "w: Almost Heaven. West Virginia.\n",
      "z2 \"D\"A A | B A3 | \"C\"E E E D | \"G\"E G3 \n",
      "w: Blue Ridge Mountains. Shennandoah River.\n",
      "z2 C C | D C3 | \"Dm\"D F F A | F4 \n",
      "w: Life is old there, older than the trees,\n",
      "\"C\"G G G G | A G3 | \"Bb\"D F F G | \"F\"F2 |\n",
      "w: younger than the mountains, blowing like the breeze.\n",
      "A | B4 | z2 B G | \"D\"A4 | z\n",
      "w: Country roads take me home\n",
      "B A | \"Em\"G4 | z2 B d | \"C\"e4 | z\n",
      "w: to the place I belong,\n",
      "e e | \"G\"d B3 | z2 B G | \"D\"A B3 | z\n",
      "w: West Virginia, mountain mama.\n",
      "B A | \"C\"G4 | z2 G A | \"G\"G4 | z4 |\n",
      "w: Take me home, country roads.\n",
      "z \"Dm\"F F F | \"C\"C\n",
      "w: I hear her voice.\n",
      "G A | \"G\"B B B B | B A G2 | \n",
      "w: In the morning hour she calls_ me.\n",
      "\"C\"c c c | \"G\"c B A G | \"D\"A2 B B | A4 \n",
      "w: Radio reminds me of my home far a-way.\n",
      "\"Em\"B B B B | \"F\"A A A A | \"C\"G \n",
      "w: Drivin' down the road I get a feeling\n",
      "A A | \"A\"A A B A | \"E\"B c B2 | z\n",
      "w: that I should have been home yes-ter-day,\n",
      "A B | c4 | z2 |\n",
      "w: Yesterday.\n",
      "z2 \"A\"E E | F E3 | z2 \"F#m\"F E | F A3 \n",
      "w: Almost Heaven. West Virginia.\n",
      "z2 \"D\"A A | B A3 | \"C\"E E E D | \"G\"E G3 \n",
      "w: Blue Ridge Mountains. Shennandoah River.\n",
      "z2 C C | D C3 | \"Dm\"D F F A | F4 \n",
      "w: Life is old there, older than the trees,\n",
      "\"C\"G G G G | A G3 | \"Bb\"D F F G | \"F\"F2 |\n",
      "w: younger than the mountains, blowing like the breeze.\n",
      "A | B4 | z2 B G | \"D\"A4 | z\n",
      "w: Country roads take me home\n",
      "B A | \"Em\"G4 | z2 B d | \"C\"e4 | z\n",
      "w: to the place I belong,\n",
      "e e | \"G\"d B3 | z2 B G | \"D\"A B3 | z\n",
      "w: West Virginia, mountain mama.\n",
      "B A | \"C\"G4 | z2 G A | \"G\"G4 | z4 |\n",
      "w: Take me home, country roads.\n",
      "z \"Dm\"F F F | \"C\"C\n",
      "w: I hear her voice.\n",
      "G A | \"G\"B B B B | B A G2 | \n",
      "w: In the morning hour she calls_ me.\n",
      "\"C\"c c c | \"G\"c B A G | \"D\"A2 B B | A4 \n",
      "w: Radio reminds me of my home far a-way.\n",
      "\"Em\"B B B B | \"F\"A A A A | \"C\"G \n",
      "w: Drivin' down the road I get a feeling\n",
      "A A | \"A\"A A B A | \"E\"B c B2 | z\n",
      "w: that I should have been home yes-ter-day,\n",
      "A B | c4 | z2 |\n",
      "w: Yesterday.\n",
      "EFG | A3 G AdcA | (GF) D\n",
      "w: Oh, Danny boy, the pipes, the pipes are calling\n",
      "G Bc | d3 e dBGB | A4 \n",
      "w: From glen to glen, and down the mountain side.\n",
      "EFG | A3 G AdcA | (GF) D\n",
      "w: The summer's gone, and all the flowers are dying.\n",
      "E FG | A3 B AGFG | F4 \n",
      "w: Tis you, 'tis you must go, and I must bide.\n",
      "def | g3 f fede | (dB) G\n",
      "w: But come you back when summer's in the meadow,\n",
      "cde | f3 e edcA | G4 \n",
      "w: Or when the valley's hushed and white with snow.\n",
      "ccc | a3 g gfdf | (cA) F\n",
      "w: 'Tis I'll be there in sunshine or in shadow\n",
      "EFG | AdcA GFDE  | F4 z |\n",
      "w: Oh, Danny boy, oh, Danny boy, I love you so.\n",
      "EFG | A3 G AdcA | (GF) D\n",
      "w: Oh, Danny boy, the pipes, the pipes are calling\n",
      "G Bc | d3 e dBGB | A4 \n",
      "w: From glen to glen, and down the mountain side.\n",
      "EFG | A3 G AdcA | (GF) D\n",
      "w: The summer's gone, and all the flowers are dying.\n",
      "E FG | A3 B AGFG | F4 \n",
      "w: Tis you, 'tis you must go, and I must bide.\n",
      "def | g3 f fede | (dB) G\n",
      "w: But come you back when summer's in the meadow,\n",
      "cde | f3 e edcA | G4 \n",
      "w: Or when the valley's hushed and white with snow.\n",
      "ccc | a3 g gfdf | (cA) F\n",
      "w: 'Tis I'll be there in sunshine or in shadow\n",
      "EFG | AdcA GFDE  | F4 z |\n",
      "w: Oh, Danny boy, oh, Danny boy, I love you so.\n",
      "\"G\"d>c   B     A | \"Em\"G   A  B   G \n",
      "w: Deck the halls with boughs of holly.\n",
      "\"D7\"A/2B/2c/2A/2 \"G\"B>A | G \"D7\"F \"G\"G2 \n",
      "w: Fa la la la la, la la la la.\n",
      "\"G\"d>c   B   A | \"Em\"G A  B   G \n",
      "w: Tis the season to be jolly.\n",
      "\"D7\"A/2B/2c/2A/2 \"G\"B>A | G \"D7\"F \"G\"G2 \n",
      "w: Fa la la la la, la la la la.\n",
      "\"D7\"A>B  c   A | \"G\"B>c d   A \n",
      "w: Don we now our gay apparel.\n",
      "\"D7\"A/2B/2c/2A/2 \"G\"B>A | G \"D7\"F \"G\"G2 \n",
      "w: Fa la la la la, la la la la.\n",
      "\"G\"d>c    B  A |   \"Em\"G A    B   G \n",
      "w: Troll the ancient Yule tide carol.\n",
      "\"D7\"A/2B/2c/2A/2 \"G\"B>A | G \"D7\"F \"G\"G2 \n",
      "w: Fa la la la la, la la la la.\n",
      "\"Em\"B2BB B2BB |\"Em\"B2E2G2B2 \n",
      "w: What shall we do with a drunken sailor,\n",
      "\"Em\"B2BB B2BB |\"Em\"B2E2G2B2 \n",
      "w: What shall we do with a drunken sailor,\n",
      "\"Em\"B2BB B2BB |\"Em\"B2E2G2B2 \n",
      "w: What shall we do with a drunken sailor,\n",
      "\"Bm\"d2B2\"D\"A2F2 |\"Em\"E4 E2 z2 |\n",
      "w: Early in the morning?\n",
      "\"Em\"B4 B3B |\"Em\"B2E2G2B2 \n",
      "w: Way, hay, and up she rises,\n",
      "\"Em\"B4 B3B |\"Em\"B2E2G2B2 \n",
      "w: Way, hay, and up she rises,\n",
      "\"Em\"B4 B3B |\"Em\"B2E2G2B2 \n",
      "w: Way, hay, and up she rises,\n",
      "\"Bm\"d2B2\"D\"A2F2 |\"Em\"E4 E2 z2 |\n",
      "w: Early in the morning.\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(len(input_texts)):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    # print('-')\n",
    "    # print(seq_index)\n",
    "    print(decoded_sentence[:-2])\n",
    "    print('w:', input_texts[seq_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "L: 1/4\n",
      "ce | e4 (3(cBA) | c4 cB | A4 F2 | E4\n",
      "w: Hello, is it me? Is it me you're looking for?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate(lyrics):\n",
    "    \n",
    "    abc = \"\";\n",
    "    input_lyrics = []\n",
    "    input_chars = set()\n",
    "    lines = lyrics.split('\\n')\n",
    "    for line in lines[: len(lines) - 1]:\n",
    "        input_lyrics.append(line)\n",
    "        #for char in line:\n",
    "            #if char not in input_chars:\n",
    "                #input_chars.add(char)\n",
    "    \n",
    "    #input_chars = sorted(list(input_chars))\n",
    "    #input_tok_index = dict([(char, i) for i, char in enumerate(input_chars)])\n",
    "    \n",
    "    encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "    \n",
    "    #print(\"Token Index: \"+ str(len(input_token_index)))\n",
    "    #print(\"Input Lyrics: \"+ str(len(input_lyrics)))\n",
    "    \n",
    "    for seq_index in range(len(input_lyrics)):\n",
    "        \n",
    "        for i in range(len(input_lyrics)):\n",
    "            for t, char in enumerate(input_lyrics[seq_index]):\n",
    "                encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "        \n",
    "        input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "        decoded_sentence = decode_sequence(input_seq)\n",
    "        abc += decoded_sentence\n",
    "        abc += \"w: \"+input_lyrics[seq_index]+\"\\n\"\n",
    "    \n",
    "    return abc\n",
    "\n",
    "print (\"---\")\n",
    "print (\"L: 1/4\\n\"+generate(\"Hello, is it me? Is it me you're looking for?\\n\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyStringsExistInList(arr):\n",
    "    \n",
    "    response = False\n",
    "    \n",
    "    for i in arr:\n",
    "        if (i == ''):\n",
    "            response = True\n",
    "    \n",
    "    return response\n",
    "\n",
    "def countNotesInSector(sector):\n",
    "    count = 0\n",
    "    allowedChars = ['A', 'B', 'C', 'D','E','F','G','a','b','c','d','e','f','g']\n",
    "    \n",
    "    for char in allowedChars:\n",
    "        count += sector.count(char)\n",
    "    \n",
    "    return count\n",
    "\n",
    "def mostCommon(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "def evaluateConsistency(abc):\n",
    "    \n",
    "    consistency = 0.0\n",
    "    \n",
    "    lines = abc.split('\\n')\n",
    "    melody_lines = []\n",
    "    sectors = []\n",
    "    stripped_sectors = []\n",
    "    melody_sectors = []\n",
    "    notes_sector = []\n",
    "    \n",
    "    sectors_count = 0\n",
    "    most_common_count = 0\n",
    "    \n",
    "    ## remove lines of lyrics\n",
    "    for line in lines:\n",
    "        if (line.startswith('w:') == False):\n",
    "            melody_lines.append(line)\n",
    "            \n",
    "    ## split each line in to sectors\n",
    "    for melody_line in melody_lines:\n",
    "        arr = melody_line.split('|')\n",
    "        for item in arr:\n",
    "            sectors.append(item)\n",
    "    \n",
    "    ## remove trailing and leading empty spaces of sectors\n",
    "    for sector in sectors:\n",
    "        stripped_sectors.append(sector.strip())\n",
    "        \n",
    "    ## remove empty sectors\n",
    "    while (emptyStringsExistInList(stripped_sectors)):\n",
    "        for stripped_sector in stripped_sectors:\n",
    "            if (stripped_sector == ''):\n",
    "                stripped_sectors.remove(stripped_sector)\n",
    "    \n",
    "    ## remove chords from sectors\n",
    "    for stripped_sector in stripped_sectors:\n",
    "        l = stripped_sector.split('\"')[1::2]\n",
    "        if (len(l) > 0):\n",
    "            melody_sectors.append(stripped_sector.replace('\"'+ l[0] +'\"',''))\n",
    "            \n",
    "    ## count number of notes in each sector\n",
    "    for melody_sector in melody_sectors:\n",
    "        notes_sector.append(countNotesInSector(melody_sector))\n",
    "        \n",
    "    ## remove single note sectors\n",
    "    #notes_sector = filter(lambda a: a != 1, notes_sector)\n",
    "        \n",
    "    ## count the occurances of most common number of notes in all sectors\n",
    "    common = mostCommon(notes_sector)\n",
    "    most_common_count = notes_sector.count(common)\n",
    "    \n",
    "    sectors_count = len(notes_sector)\n",
    "    \n",
    "    consistency = float(most_common_count)/ float(sectors_count)\n",
    "    \n",
    "    return consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency: 0.666666666667\n"
     ]
    }
   ],
   "source": [
    "## Testing Consistency Evaluation Algorithm\n",
    "\n",
    "#input_lyrics = \"So, so you think you can tell\\nHeaven from hell\\nBlue skies from pain\\nCan you tell a green field\\nFrom a cold steel rail?\\nA smile from a veil?\\nDo you think you can tell?\";\n",
    "\n",
    "#print (generate(input_lyrics))\n",
    "#print (\"Consistency: \"+ str(evaluateConsistency(generate(input_lyrics))))\n",
    "\n",
    "\n",
    "#print (\"Consistency: \"+ str(evaluateConsistency('A/2A/2 | \"G\"G G G A | B d2 d/2d/2 | \"C\"e e g g | \"G\"d3\\nw: My Name is Something Something.\\nA/2A/2 | \"G\"G G G A | B d2 d/2d/2 | \"C\"e e g g | \"G\"d3\\nw: My Name is Something Something.\\nA/2A/2 | \"G\"G G G A | B d2 d/2d/2 | \"C\"e e g g | \"G\"d3\\nw: My Name is Something Something.\\nA/2A/2 | \"G\"G G G A | B d2 d/2d/2 | \"C\"e e g g | \"G\"d3\\nw: My Name is Something Something.')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
